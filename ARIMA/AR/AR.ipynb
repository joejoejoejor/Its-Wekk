{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>PM10_Combined_Trend_Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>75.197962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>51.472071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>32.710483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>24.801767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>9.683660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datum  PM10_Combined_Trend_Residual\n",
       "0  2022-01-01 00:00:00+00:00                     75.197962\n",
       "1  2022-01-01 01:00:00+00:00                     51.472071\n",
       "2  2022-01-01 02:00:00+00:00                     32.710483\n",
       "3  2022-01-01 03:00:00+00:00                     24.801767\n",
       "4  2022-01-01 04:00:00+00:00                      9.683660"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "x = pd.read_csv('../AR/50MostImpFeatures_DF.csv')\n",
    "y = pd.read_csv('../AR/TargetCutto50MostImpFeatures_DF.csv')\n",
    "\n",
    "y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMAX MSE: 28.737498819413833\n",
      "SARIMAX MSE: 33.32387913169761\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the order for ARIMA and SARIMA models\n",
    "arima_order = (1, 1, 1)\n",
    "sarima_order = (1, 1, 1)\n",
    "seasonal_order = (1, 1, 1, 12)  # Example seasonal order\n",
    "\n",
    "# Fit ARIMAX model\n",
    "arimax_model = ARIMA(endog=y['PM10_Combined_Trend_Residual'], exog=x, order=arima_order)\n",
    "arimax_fit = arimax_model.fit()\n",
    "\n",
    "# Fit SARIMAX model\n",
    "sarimax_model = SARIMAX(endog=y['PM10_Combined_Trend_Residual'], exog=x, order=sarima_order, seasonal_order=seasonal_order)\n",
    "sarimax_fit = sarimax_model.fit(disp=False)\n",
    "\n",
    "# Make predictions\n",
    "arimax_predictions = arimax_fit.forecast(steps=len(y_validate), exog=x_validate)\n",
    "sarimax_predictions = sarimax_fit.forecast(steps=len(y_validate), exog=x_validate)\n",
    "\n",
    "# Calculate MSE\n",
    "arimax_mse = mean_squared_error(y_validate['PM10_Combined_Trend_Residual'], arimax_predictions)\n",
    "sarimax_mse = mean_squared_error(y_validate['PM10_Combined_Trend_Residual'], sarimax_predictions)\n",
    "\n",
    "print(f\"ARIMAX MSE: {arimax_mse}\")\n",
    "print(f\"SARIMAX MSE: {sarimax_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "SARIMAX models require univariate `endog`. Got shape (2871, 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m x_train_cv, x_test_cv \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39miloc[train_index], x_train\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Fit ARIMA model\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m ar_model \u001b[38;5;241m=\u001b[39m fit_arima(y_train_cv, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     40\u001b[0m ar_predictions \u001b[38;5;241m=\u001b[39m ar_model\u001b[38;5;241m.\u001b[39mforecast(steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(y_test_cv))\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Fit MA model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m, in \u001b[0;36mfit_arima\u001b[1;34m(train, order)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_arima\u001b[39m(train, order):\n\u001b[1;32m---> 21\u001b[0m     model \u001b[38;5;241m=\u001b[39m ARIMA(train, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m     22\u001b[0m     model_fit \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_fit\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\arima\\model.py:158\u001b[0m, in \u001b[0;36mARIMA.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[0;32m    151\u001b[0m     trend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Construct the specification\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# (don't pass specific values of enforce stationarity/invertibility,\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# because we don't actually want to restrict the estimators based on\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# this criteria. Instead, we'll just make sure that the parameter\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# estimates from those methods satisfy the criteria.)\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec_arima \u001b[38;5;241m=\u001b[39m SARIMAXSpecification(\n\u001b[0;32m    159\u001b[0m     endog, exog\u001b[38;5;241m=\u001b[39mexog, order\u001b[38;5;241m=\u001b[39morder, seasonal_order\u001b[38;5;241m=\u001b[39mseasonal_order,\n\u001b[0;32m    160\u001b[0m     trend\u001b[38;5;241m=\u001b[39mtrend, enforce_stationarity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, enforce_invertibility\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    161\u001b[0m     concentrate_scale\u001b[38;5;241m=\u001b[39mconcentrate_scale, trend_offset\u001b[38;5;241m=\u001b[39mtrend_offset,\n\u001b[0;32m    162\u001b[0m     dates\u001b[38;5;241m=\u001b[39mdates, freq\u001b[38;5;241m=\u001b[39mfreq, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    163\u001b[0m     validate_specification\u001b[38;5;241m=\u001b[39mvalidate_specification)\n\u001b[0;32m    164\u001b[0m exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec_arima\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39morig_exog\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Raise an error if we have a constant in an integrated model\u001b[39;00m\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\arima\\specification.py:454\u001b[0m, in \u001b[0;36mSARIMAXSpecification.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# Validate endog shape\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (validate_specification \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m faux_endog \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSARIMAX models require univariate `endog`. Got\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    455\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m shape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_missing \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m faux_endog \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog)))\n",
      "\u001b[1;31mValueError\u001b[0m: SARIMAX models require univariate `endog`. Got shape (2871, 2)."
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Ensure data is numeric and handle missing values\n",
    "x = x.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "y = y.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# Train-test-validation split for x (features) and y (target variable)\n",
    "train_size = int(len(y) * 0.7)\n",
    "test_size = int(len(y) * 0.2)\n",
    "validate_size = len(y) - train_size - test_size\n",
    "\n",
    "x_train, x_test, x_validate = np.split(x, [train_size, train_size + test_size])\n",
    "y_train, y_test, y_validate = np.split(y, [train_size, train_size + test_size])\n",
    "\n",
    "# Function to fit and predict using ARIMA model\n",
    "def fit_arima(train, order):\n",
    "    model = ARIMA(train, order=order)\n",
    "    model_fit = model.fit()\n",
    "    return model_fit\n",
    "\n",
    "# Function to fit and predict using SARIMA model\n",
    "def fit_sarima(train, order, seasonal_order):\n",
    "    model = SARIMAX(train, order=order, seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit(disp=False)\n",
    "    return model_fit\n",
    "\n",
    "# Expanding cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, test_index in tscv.split(y_train):\n",
    "    # Use .iloc for position-based indexing\n",
    "    y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    x_train_cv, x_test_cv = x_train.iloc[train_index], x_train.iloc[test_index]\n",
    "\n",
    "    # Fit ARIMA model\n",
    "    ar_model = fit_arima(y_train_cv, order=(1, 0, 0))\n",
    "    ar_predictions = ar_model.forecast(steps=len(y_test_cv))\n",
    "    \n",
    "    # Fit MA model\n",
    "    ma_model = fit_arima(y_train_cv, order=(0, 0, 1))\n",
    "    ma_predictions = ma_model.forecast(steps=len(y_test_cv))\n",
    "    \n",
    "    # Fit ARMA model\n",
    "    arma_model = fit_arima(y_train_cv, order=(1, 0, 1))\n",
    "    arma_predictions = arma_model.forecast(steps=len(y_test_cv))\n",
    "    \n",
    "    # Fit SARIMA model (ensure univariate time series)\n",
    "    sarima_model = fit_sarima(y_train_cv['PM10_Combined_Trend_Residual'], order=(1, 0, 1), seasonal_order=(1, 1, 1, 12))\n",
    "    sarima_predictions = sarima_model.forecast(steps=len(y_test_cv))\n",
    "    \n",
    "    # Evaluate models on the test set (y_test_cv)\n",
    "    ar_mse_test = mean_squared_error(y_test_cv, ar_predictions)\n",
    "    ma_mse_test = mean_squared_error(y_test_cv, ma_predictions)\n",
    "    arma_mse_test = mean_squared_error(y_test_cv, arma_predictions)\n",
    "    sarima_mse_test = mean_squared_error(y_test_cv, sarima_predictions)\n",
    "\n",
    "    # Evaluate models on the validation set (y_validate)\n",
    "    ar_mse_validate = mean_squared_error(y_validate, ar_model.forecast(steps=len(y_validate)))\n",
    "    ma_mse_validate = mean_squared_error(y_validate, ma_model.forecast(steps=len(y_validate)))\n",
    "    arma_mse_validate = mean_squared_error(y_validate, arma_model.forecast(steps=len(y_validate)))\n",
    "    sarima_mse_validate = mean_squared_error(y_validate, sarima_model.forecast(steps=len(y_validate)))\n",
    "\n",
    "    # Print results\n",
    "    print(\"AR MSE Test:\", ar_mse_test)\n",
    "    print(\"MA MSE Test:\", ma_mse_test)\n",
    "    print(\"ARMA MSE Test:\", arma_mse_test)\n",
    "    print(\"SARIMA MSE Test:\", sarima_mse_test)\n",
    "    print(\"AR MSE Validate:\", ar_mse_validate)\n",
    "    print(\"MA MSE Validate:\", ma_mse_validate)\n",
    "    print(\"ARMA MSE Validate:\", arma_mse_validate)\n",
    "    print(\"SARIMA MSE Validate:\", sarima_mse_validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Progrem\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold   Model    MSE Test   MSE Validate   \n",
      "========================================\n",
      "1      AR       40.5705    89.5497        \n",
      "1      MA       38.2466    85.3100        \n",
      "1      ARMA     40.7036    89.8140        \n",
      "1      SARIMA   38.6565    84.9547        \n",
      "2      AR       27.9202    58.7961        \n",
      "2      MA       27.6984    57.7342        \n",
      "2      ARMA     28.0045    59.1488        \n",
      "2      SARIMA   27.1645    39.7247        \n",
      "3      AR       72.1517    53.5400        \n",
      "3      MA       72.4485    53.3734        \n",
      "3      ARMA     72.0366    53.5554        \n",
      "3      SARIMA   73.1516    56.2175        \n",
      "4      AR       52.0502    47.0926        \n",
      "4      MA       52.2094    46.9250        \n",
      "4      ARMA     51.8040    46.4819        \n",
      "4      SARIMA   60.0484    20.0369        \n",
      "5      AR       48.0416    44.4847        \n",
      "5      MA       48.1294    43.3521        \n",
      "5      ARMA     48.0965    45.4195        \n",
      "5      SARIMA   36.2654    30.0752        \n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Train-test-validation split\n",
    "train_size = int(len(y) * 0.7)\n",
    "test_size = int(len(y) * 0.2)\n",
    "validate_size = len(y) - train_size - test_size\n",
    "\n",
    "train, test, validate = np.split(y['PM10_Combined_Trend_Residual'], [train_size, train_size + test_size])\n",
    "\n",
    "# Function to fit and predict using ARIMA model\n",
    "def fit_arima(train, order):\n",
    "    model = ARIMA(train, order=order)\n",
    "    model_fit = model.fit()\n",
    "    return model_fit\n",
    "\n",
    "# Function to fit and predict using SARIMA model\n",
    "def fit_sarima(train, order, seasonal_order):\n",
    "    model = SARIMAX(train, order=order, seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit()\n",
    "    return model_fit\n",
    "\n",
    "# Expanding cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "fold = 1\n",
    "\n",
    "print(f\"{'Fold':<6} {'Model':<8} {'MSE Test':<10} {'MSE Validate':<15}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for train_index, test_index in tscv.split(train):\n",
    "    train_cv, test_cv = train[train_index], train[test_index]\n",
    "    \n",
    "    models = {\n",
    "        \"AR\": fit_arima(train_cv, order=(1, 0, 0)),\n",
    "        \"MA\": fit_arima(train_cv, order=(0, 0, 1)),\n",
    "        \"ARMA\": fit_arima(train_cv, order=(1, 0, 1)),\n",
    "        \"SARIMA\": fit_sarima(train_cv, order=(1, 0, 1), seasonal_order=(1, 1, 1, 12))\n",
    "    }\n",
    "\n",
    "    for model_name, model_fit in models.items():\n",
    "        predictions_test = model_fit.forecast(steps=len(test_cv))\n",
    "        predictions_validate = model_fit.forecast(steps=len(validate))\n",
    "        \n",
    "        # Calculate MSE\n",
    "        mse_test = mean_squared_error(test_cv, predictions_test)\n",
    "        mse_validate = mean_squared_error(validate, predictions_validate)\n",
    "        \n",
    "        print(f\"{fold:<6} {model_name:<8} {mse_test:<10.4f} {mse_validate:<15.4f}\")\n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "mean_target = y['PM10_Combined_Trend_Residual'].mean()\n",
    "mean_target\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.481885093511329"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mean_target = y['PM10_Combined_Trend_Residual'].mean()\n",
    "mean_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.294967954185212"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_target = y['PM10_Combined_Trend_Residual'].std()\n",
    "std_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Progrem\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold   Model    MSE Test   MSE Validate   \n",
      "========================================\n",
      "1      AR       84.2168    53.7141        \n",
      "1      MA       84.9976    53.4333        \n",
      "1      ARMA     83.9558    53.7641        \n",
      "1      SARIMA   83.6112    54.8880        \n",
      "2      AR       53.6145    55.5490        \n",
      "2      MA       52.6968    54.2958        \n",
      "2      ARMA     53.7630    55.7384        \n",
      "2      SARIMA   112.9097   108.8282       \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 49\u001b[0m\n\u001b[0;32m     42\u001b[0m test_cv \u001b[38;5;241m=\u001b[39m train[test_start:test_end]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Fit models for this fold\u001b[39;00m\n\u001b[0;32m     45\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR\u001b[39m\u001b[38;5;124m\"\u001b[39m: fit_arima(train_cv, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMA\u001b[39m\u001b[38;5;124m\"\u001b[39m: fit_arima(train_cv, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mARMA\u001b[39m\u001b[38;5;124m\"\u001b[39m: fit_arima(train_cv, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSARIMA\u001b[39m\u001b[38;5;124m\"\u001b[39m: fit_sarima(train_cv, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m), seasonal_order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m24\u001b[39m))\n\u001b[0;32m     50\u001b[0m }\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model_fit \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     53\u001b[0m     predictions_test \u001b[38;5;241m=\u001b[39m model_fit\u001b[38;5;241m.\u001b[39mforecast(steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_cv))\n",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m, in \u001b[0;36mfit_sarima\u001b[1;34m(train, order, seasonal_order)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_sarima\u001b[39m(train, order, seasonal_order):\n\u001b[0;32m     21\u001b[0m     model \u001b[38;5;241m=\u001b[39m SARIMAX(train, order\u001b[38;5;241m=\u001b[39morder, seasonal_order\u001b[38;5;241m=\u001b[39mseasonal_order)\n\u001b[1;32m---> 22\u001b[0m     model_fit \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_fit\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:703\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[1;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[0;32m    701\u001b[0m         flags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhessian_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m optim_hessian\n\u001b[0;32m    702\u001b[0m     fargs \u001b[38;5;241m=\u001b[39m (flags,)\n\u001b[1;32m--> 703\u001b[0m     mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(start_params, method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    704\u001b[0m                          fargs\u001b[38;5;241m=\u001b[39mfargs,\n\u001b[0;32m    705\u001b[0m                          maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m    706\u001b[0m                          full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[0;32m    707\u001b[0m                          disp\u001b[38;5;241m=\u001b[39mdisp, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    708\u001b[0m                          skip_hessian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    710\u001b[0m \u001b[38;5;66;03m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_params:\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:566\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_t\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    565\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer()\n\u001b[1;32m--> 566\u001b[0m xopt, retvals, optim_settings \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39m_fit(f, score, start_params,\n\u001b[0;32m    567\u001b[0m                                                fargs, kwargs,\n\u001b[0;32m    568\u001b[0m                                                hessian\u001b[38;5;241m=\u001b[39mhess,\n\u001b[0;32m    569\u001b[0m                                                method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    570\u001b[0m                                                disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[0;32m    571\u001b[0m                                                maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m    572\u001b[0m                                                callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    573\u001b[0m                                                retall\u001b[38;5;241m=\u001b[39mretall,\n\u001b[0;32m    574\u001b[0m                                                full_output\u001b[38;5;241m=\u001b[39mfull_output)\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[0;32m    576\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:243\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[1;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[0;32m    240\u001b[0m     fit_funcs\u001b[38;5;241m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[0;32m    242\u001b[0m func \u001b[38;5;241m=\u001b[39m fit_funcs[method]\n\u001b[1;32m--> 243\u001b[0m xopt, retvals \u001b[38;5;241m=\u001b[39m func(objective, gradient, start_params, fargs, kwargs,\n\u001b[0;32m    244\u001b[0m                      disp\u001b[38;5;241m=\u001b[39mdisp, maxiter\u001b[38;5;241m=\u001b[39mmaxiter, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    245\u001b[0m                      retall\u001b[38;5;241m=\u001b[39mretall, full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[0;32m    246\u001b[0m                      hess\u001b[38;5;241m=\u001b[39mhessian)\n\u001b[0;32m    248\u001b[0m optim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_params\u001b[39m\u001b[38;5;124m'\u001b[39m: start_params,\n\u001b[0;32m    249\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_output\u001b[39m\u001b[38;5;124m'\u001b[39m: full_output,\n\u001b[0;32m    250\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfargs\u001b[39m\u001b[38;5;124m'\u001b[39m: fargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[0;32m    251\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretall\u001b[39m\u001b[38;5;124m'\u001b[39m: retall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_fit_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m: extra_fit_funcs}\n\u001b[0;32m    252\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\optimizer.py:660\u001b[0m, in \u001b[0;36m_fit_lbfgs\u001b[1;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m approx_grad:\n\u001b[0;32m    658\u001b[0m     func \u001b[38;5;241m=\u001b[39m f\n\u001b[1;32m--> 660\u001b[0m retvals \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mfmin_l_bfgs_b(func, start_params, maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m    661\u001b[0m                                  callback\u001b[38;5;241m=\u001b[39mcallback, args\u001b[38;5;241m=\u001b[39mfargs,\n\u001b[0;32m    662\u001b[0m                                  bounds\u001b[38;5;241m=\u001b[39mbounds, disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[0;32m    663\u001b[0m                                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kwargs)\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[0;32m    666\u001b[0m     xopt, fopt, d \u001b[38;5;241m=\u001b[39m retvals\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:237\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    225\u001b[0m callback \u001b[38;5;241m=\u001b[39m _wrap_callback(callback)\n\u001b[0;32m    226\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m'\u001b[39m: iprint,\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxcor\u001b[39m\u001b[38;5;124m'\u001b[39m: m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxls\u001b[39m\u001b[38;5;124m'\u001b[39m: maxls}\n\u001b[1;32m--> 237\u001b[0m res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args\u001b[38;5;241m=\u001b[39margs, jac\u001b[38;5;241m=\u001b[39mjac, bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m    238\u001b[0m                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[0;32m    239\u001b[0m d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    240\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    241\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuncalls\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    242\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    243\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarnflag\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[0;32m    244\u001b[0m f \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:297\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[1;32m--> 267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad_impl()\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:181\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m approx_derivative(fun_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, f0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf,\n\u001b[0;32m    182\u001b[0m                            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfinite_diff_options)\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:519\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    516\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[0;32m    520\u001b[0m                              use_one_sided, method)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:590\u001b[0m, in \u001b[0;36m_dense_difference\u001b[1;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[0;32m    588\u001b[0m     x \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[0;32m    589\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     df \u001b[38;5;241m=\u001b[39m fun(x) \u001b[38;5;241m-\u001b[39m f0\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[0;32m    592\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:470\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(x\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    468\u001b[0m     x \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(x, x0\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 470\u001b[0m f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(fun(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    473\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:534\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[1;34m(params, *args)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglike(params, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m/\u001b[39m nobs\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:938\u001b[0m, in \u001b[0;36mMLEModel.loglike\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complex_step:\n\u001b[0;32m    936\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minversion_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m INVERT_UNIVARIATE \u001b[38;5;241m|\u001b[39m SOLVE_LU\n\u001b[1;32m--> 938\u001b[0m loglike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssm\u001b[38;5;241m.\u001b[39mloglike(complex_step\u001b[38;5;241m=\u001b[39mcomplex_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    940\u001b[0m \u001b[38;5;66;03m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;66;03m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;66;03m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loglike\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:1001\u001b[0m, in \u001b[0;36mKalmanFilter.loglike\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;124;03mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;124;03m    The joint loglikelihood.\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    999\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1000\u001b[0m                   MEMORY_CONSERVE \u001b[38;5;241m^\u001b[39m MEMORY_NO_LIKELIHOOD)\n\u001b[1;32m-> 1001\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1002\u001b[0m loglikelihood_burn \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloglikelihood_burn\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1003\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglikelihood_burn)\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m&\u001b[39m MEMORY_NO_LIKELIHOOD):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Train-test-validation split\n",
    "train_size = int(len(y) * 0.7)\n",
    "test_size = int(len(y) * 0.2)\n",
    "validate_size = len(y) - train_size - test_size\n",
    "\n",
    "train, test, validate = np.split(y['PM10_Combined_Trend_Residual'], [train_size, train_size + test_size])\n",
    "\n",
    "# Function to fit and predict using ARIMA model\n",
    "def fit_arima(train, order):\n",
    "    model = ARIMA(train, order=order)\n",
    "    model_fit = model.fit()\n",
    "    return model_fit\n",
    "\n",
    "# Function to fit and predict using SARIMA model\n",
    "def fit_sarima(train, order, seasonal_order):\n",
    "    model = SARIMAX(train, order=order, seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit()\n",
    "    return model_fit\n",
    "\n",
    "# Expanding cross-validation parameters\n",
    "initial_train_size = int(len(train) * 0.5)  # Use 50% of training data as the initial training size\n",
    "test_size = int(len(train) * 0.1)  # Test size (adjust as needed)\n",
    "n_splits = (len(train) - initial_train_size) // test_size\n",
    "\n",
    "fold = 1\n",
    "print(f\"{'Fold':<6} {'Model':<8} {'MSE Test':<10} {'MSE Validate':<15}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Expanding Cross-Validation\n",
    "for fold in range(1, n_splits + 1):\n",
    "    # Define training and test sets for each fold\n",
    "    train_end = initial_train_size + (fold - 1) * test_size\n",
    "    test_start = train_end\n",
    "    test_end = train_end + test_size\n",
    "\n",
    "    train_cv = train[:train_end]\n",
    "    test_cv = train[test_start:test_end]\n",
    "\n",
    "    # Fit models for this fold\n",
    "    models = {\n",
    "        \"AR\": fit_arima(train_cv, order=(1, 0, 0)),\n",
    "        \"MA\": fit_arima(train_cv, order=(0, 0, 1)),\n",
    "        \"ARMA\": fit_arima(train_cv, order=(1, 0, 1)),\n",
    "        \"SARIMA\": fit_sarima(train_cv, order=(1, 0, 1), seasonal_order=(1, 1, 1, 24))\n",
    "    }\n",
    "\n",
    "    for model_name, model_fit in models.items():\n",
    "        predictions_test = model_fit.forecast(steps=len(test_cv))\n",
    "        predictions_validate = model_fit.forecast(steps=len(validate))\n",
    "        \n",
    "        # Calculate MSE\n",
    "        mse_test = mean_squared_error(test_cv, predictions_test)\n",
    "        mse_validate = mean_squared_error(validate, predictions_validate)\n",
    "        \n",
    "        print(f\"{fold:<6} {model_name:<8} {mse_test:<10.4f} {mse_validate:<15.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA Params: (1, 1, 1) with MSE 1.0001175376862573e-05\n",
      "Best SARIMA Params: ((1, 1, 1), (0, 0, 0, 24)) with MSE 1.0001175376862573e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results: ARIMA MSE = 400.09975129206083, SARIMA MSE = 400.09975129206083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Progrem\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Example dataset (replace 'y' with your actual dataset)\n",
    "n_points = 100\n",
    "data = np.arange(n_points)\n",
    "\n",
    "# Train-test-validation split\n",
    "train_size = int(len(data) * 0.7)\n",
    "test_size = int(len(data) * 0.2)\n",
    "validate_size = len(data) - train_size - test_size\n",
    "\n",
    "train, test, validate = np.split(data, [train_size, train_size + test_size])\n",
    "\n",
    "# Define hyperparameter ranges\n",
    "p = d = q = range(0, 2)  # Smaller ranges for ARIMA(p, d, q)\n",
    "P = D = Q = range(0, 1)  # Smaller ranges for SARIMA(P, D, Q)\n",
    "m = [24]  # Seasonal period (hourly data with daily seasonality)\n",
    "\n",
    "# Generate all ARIMA combinations\n",
    "arima_combinations = list(itertools.product(p, d, q))\n",
    "sarima_combinations = list(itertools.product(p, d, q, P, D, Q, m))\n",
    "\n",
    "# Expanding cross-validation parameters\n",
    "initial_train_size = int(len(train) * 0.5)  # 50% initial train size\n",
    "test_size = int(len(train) * 0.1)  # Test size\n",
    "n_splits = (len(train) - initial_train_size) // test_size\n",
    "\n",
    "# Function to fit ARIMA model\n",
    "def fit_arima(train, order):\n",
    "    try:\n",
    "        model = ARIMA(train, order=order)\n",
    "        model_fit = model.fit()\n",
    "        return model_fit\n",
    "    except Exception as e:\n",
    "        print(f\"ARIMA failed for order={order}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to fit SARIMA model\n",
    "def fit_sarima(train, order, seasonal_order):\n",
    "    try:\n",
    "        model = SARIMAX(train, order=order, seasonal_order=seasonal_order)\n",
    "        model_fit = model.fit(disp=False, maxiter=500)\n",
    "        return model_fit\n",
    "    except Exception as e:\n",
    "        print(f\"SARIMA failed for order={order}, seasonal_order={seasonal_order}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Hyperparameter tuning\n",
    "best_arima = None\n",
    "best_arima_mse = float(\"inf\")\n",
    "best_arima_params = None\n",
    "\n",
    "best_sarima = None\n",
    "best_sarima_mse = float(\"inf\")\n",
    "best_sarima_params = None\n",
    "\n",
    "# Loop through ARIMA hyperparameter combinations\n",
    "for order in arima_combinations:\n",
    "    fold_mse = []\n",
    "    for fold in range(1, n_splits + 1):\n",
    "        # Expanding window logic\n",
    "        train_end = initial_train_size + (fold - 1) * test_size\n",
    "        test_start = train_end\n",
    "        test_end = train_end + test_size\n",
    "\n",
    "        train_cv = train[:train_end]\n",
    "        test_cv = train[test_start:test_end]\n",
    "\n",
    "        # Fit ARIMA model\n",
    "        arima_model = fit_arima(train_cv, order=order)\n",
    "        if arima_model is not None:\n",
    "            predictions = arima_model.forecast(steps=len(test_cv))\n",
    "            mse = mean_squared_error(test_cv, predictions)\n",
    "            fold_mse.append(mse)\n",
    "\n",
    "    # Average MSE across folds\n",
    "    avg_mse = np.mean(fold_mse) if fold_mse else float(\"inf\")\n",
    "    if avg_mse < best_arima_mse:\n",
    "        best_arima_mse = avg_mse\n",
    "        best_arima_params = order\n",
    "\n",
    "# Loop through SARIMA hyperparameter combinations\n",
    "for order in itertools.product(p, d, q):\n",
    "    for seasonal_order in itertools.product(P, D, Q, m):\n",
    "        fold_mse = []\n",
    "        for fold in range(1, n_splits + 1):\n",
    "            train_end = initial_train_size + (fold - 1) * test_size\n",
    "            test_start = train_end\n",
    "            test_end = train_end + test_size\n",
    "\n",
    "            train_cv = train[:train_end]\n",
    "            test_cv = train[test_start:test_end]\n",
    "\n",
    "            # Fit SARIMA model\n",
    "            sarima_model = fit_sarima(train_cv, order=order, seasonal_order=seasonal_order)\n",
    "            if sarima_model is not None:\n",
    "                predictions = sarima_model.forecast(steps=len(test_cv))\n",
    "                mse = mean_squared_error(test_cv, predictions)\n",
    "                fold_mse.append(mse)\n",
    "\n",
    "        # Average MSE across folds\n",
    "        avg_mse = np.mean(fold_mse) if fold_mse else float(\"inf\")\n",
    "        if avg_mse < best_sarima_mse:\n",
    "            best_sarima_mse = avg_mse\n",
    "            best_sarima_params = (order, seasonal_order)\n",
    "\n",
    "# Final evaluation on validation set using best parameters\n",
    "print(f\"Best ARIMA Params: {best_arima_params} with MSE {best_arima_mse}\")\n",
    "print(f\"Best SARIMA Params: {best_sarima_params} with MSE {best_sarima_mse}\")\n",
    "\n",
    "final_arima_model = fit_arima(train, order=best_arima_params)\n",
    "final_arima_predictions = final_arima_model.forecast(steps=len(validate)) if final_arima_model else []\n",
    "final_arima_mse = mean_squared_error(validate, final_arima_predictions) if final_arima_model else float(\"inf\")\n",
    "\n",
    "final_sarima_model = fit_sarima(train, order=best_sarima_params[0], seasonal_order=best_sarima_params[1])\n",
    "final_sarima_predictions = final_sarima_model.forecast(steps=len(validate)) if final_sarima_model else []\n",
    "final_sarima_mse = mean_squared_error(validate, final_sarima_predictions) if final_sarima_model else float(\"inf\")\n",
    "\n",
    "print(f\"Validation Results: ARIMA MSE = {final_arima_mse}, SARIMA MSE = {final_sarima_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
