{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>PM10_Combined_Trend_Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>75.197962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>51.472071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>32.710483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>24.801767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>9.683660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datum  PM10_Combined_Trend_Residual\n",
       "0  2022-01-01 00:00:00+00:00                     75.197962\n",
       "1  2022-01-01 01:00:00+00:00                     51.472071\n",
       "2  2022-01-01 02:00:00+00:00                     32.710483\n",
       "3  2022-01-01 03:00:00+00:00                     24.801767\n",
       "4  2022-01-01 04:00:00+00:00                      9.683660"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "y = pd.read_csv('../Detrended DAta/TargetCutto50MostImpFeatures_DF.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -4.604578602914901\n",
      "p-value: 0.00012668277472821596\n",
      "The series is stationary.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Perform the Augmented Dickey-Fuller test\n",
    "adf_test = adfuller(y['PM10_Combined_Trend_Residual'])\n",
    "\n",
    "# Extract and print the test statistic and p-value\n",
    "adf_statistic = adf_test[0]\n",
    "p_value = adf_test[1]\n",
    "\n",
    "print(f'ADF Statistic: {adf_statistic}')\n",
    "print(f'p-value: {p_value}')\n",
    "\n",
    "# Check if the p-value is less than the significance level (e.g., 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"The series is stationary.\")\n",
    "else:\n",
    "    print(\"The series is not stationary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       1          2          3          4          5          6          7          8          9          10         11         12         13         14         15         16         17         18         19         20         21         22         23         24\n",
      "Test MSE        83.520059  80.194799  82.802817  82.484601  82.148029  78.614943  75.363332  73.478573  72.069796  70.744455  69.440469  70.296847  71.530207  73.199264  70.980494  66.884957  64.702587  67.133300  66.330506  67.377807  69.670836  70.746059  71.658436  73.719455\n",
      "Test MAE         9.138931   8.955155   9.099605   9.082103   9.063555   8.866507   8.681206   8.571964   8.489393   8.410972   8.333095   8.384321   8.457553   8.555657   8.424992   8.178322   8.043792   8.193491   8.144354   8.208399   8.346906   8.411068   8.465131   8.586003\n",
      "Validation MSE  42.906973  40.533155  42.393327  42.165722  41.925179  39.412246  37.119972  35.800775  34.819484  33.900142  32.999342  33.590509  34.444736  35.605893  34.063597  31.245114  29.759233  31.414925  30.866522  31.582254  33.158207  33.901252  34.533736  35.968974\n",
      "Validation MAE   6.550341   6.366565   6.511016   6.493514   6.474966   6.277917   6.092616   5.983375   5.900804   5.822383   5.744505   5.795732   5.868964   5.967067   5.836403   5.589733   5.455202   5.604902   5.555765   5.619809   5.758316   5.822478   5.876541   5.997414\n"
     ]
    }
   ],
   "source": [
    "# Define results DataFrame to store MSE and MAE for test and validation sets separately\n",
    "results_test = pd.DataFrame(np.zeros((2, 24)))  # MSE and MAE for test set\n",
    "results_test.columns = np.arange(1, 25)\n",
    "results_test.index = [\"Test MSE\", \"Test MAE\"]\n",
    "\n",
    "results_validate = pd.DataFrame(np.zeros((2, 24)))  # MSE and MAE for validation set\n",
    "results_validate.columns = np.arange(1, 25)\n",
    "results_validate.index = [\"Validation MSE\", \"Validation MAE\"]\n",
    "\n",
    "# Function to fit ARIMA model and compute MSE and MAE\n",
    "def fit_arima(p, training_data, testing, validation):\n",
    "    mod = sm.tsa.ARIMA(training_data['PM10_Combined_Trend_Residual'], order=(p, 0, 0))\n",
    "    res = mod.fit()\n",
    "    \n",
    "    # One-step ahead forecast for the testing set\n",
    "    forecast_test = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # One-step ahead forecast for the validation set\n",
    "    forecast_validate = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # Calculate Mean Squared Error for the test set\n",
    "    mse_test = ((testing['PM10_Combined_Trend_Residual'].values[:1] - forecast_test.values) ** 2).mean()\n",
    "    \n",
    "    # Calculate Mean Squared Error for the validation set\n",
    "    mse_validate = ((validation['PM10_Combined_Trend_Residual'].values[:1] - forecast_validate.values) ** 2).mean()\n",
    "    \n",
    "    # Calculate Mean Absolute Error for the test set\n",
    "    mae_test = np.abs(testing['PM10_Combined_Trend_Residual'].values[:1] - forecast_test.values).mean()\n",
    "    \n",
    "    # Calculate Mean Absolute Error for the validation set\n",
    "    mae_validate = np.abs(validation['PM10_Combined_Trend_Residual'].values[:1] - forecast_validate.values).mean()\n",
    "    \n",
    "    return mse_test, mae_test, mse_validate, mae_validate\n",
    "\n",
    "# Use joblib's Parallel to run the fit_arima function in parallel for different p values\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_arima)(p, y, testing, validation) for p in range(1, 25))\n",
    "\n",
    "# Store the results in the DataFrame\n",
    "for idx, (mse_test, mae_test, mse_validate, mae_validate) in enumerate(results):\n",
    "    p_value = idx + 1\n",
    "    results_test.loc[\"Test MSE\", p_value] = mse_test\n",
    "    results_test.loc[\"Test MAE\", p_value] = mae_test\n",
    "    results_validate.loc[\"Validation MSE\", p_value] = mse_validate\n",
    "    results_validate.loc[\"Validation MAE\", p_value] = mae_validate\n",
    "\n",
    "# Combine the results into one DataFrame for better display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0, ignore_index=False)\n",
    "\n",
    "# Print the results in a more readable format\n",
    "print(final_results.to_string(index=True))  # Display the results in a tabular format\n",
    "\n",
    "\n",
    "#runtime 2m 30s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MA Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      q=1        q=2        q=3        q=4        q=5        q=6        q=7        q=8        q=9       q=10       q=11       q=12       q=13       q=14       q=15       q=16       q=17       q=18       q=19       q=20       q=21       q=22       q=23       q=24\n",
      "Test MSE        65.985091  67.075365  75.850070  68.614055  72.051681  77.651255  80.237003  85.623280  88.091847  90.037087  89.543566  88.571507  84.446137  82.698232  85.086645  89.222751  86.498848  85.654038  84.528418  82.907342  80.484712  79.632375  77.503295  78.043470\n",
      "Test MAE         8.123121   8.189955   8.709195   8.283360   8.488326   8.811995   8.957511   9.253285   9.385726   9.488787   9.462746   9.411244   9.189458   9.093857   9.224242   9.445780   9.300476   9.254947   9.193934   9.105347   8.971327   8.923697   8.803596   8.834222\n",
      "Validation MSE  30.631036  31.375297  37.461806  32.430413  34.806893  38.730776  40.563161  44.418164  46.201061  47.612732  47.254031  46.548610  43.571465  42.318504  44.031888  47.021055  45.049417  44.440319  43.630574  42.468127  40.739341  40.133592  38.626301  39.007920\n",
      "Validation MAE   5.534531   5.601366   6.120605   5.694771   5.899737   6.223405   6.368921   6.664695   6.797136   6.900198   6.874157   6.822654   6.600868   6.505267   6.635653   6.857190   6.711886   6.666357   6.605344   6.516757   6.382738   6.335108   6.215006   6.245632\n"
     ]
    }
   ],
   "source": [
    "# Define results DataFrame to store MSE and MAE for test and validation sets separately\n",
    "results_test = pd.DataFrame(np.zeros((2, 24)))  # MSE and MAE for test set\n",
    "results_test.columns = [f\"q={q}\" for q in range(1, 25)]  # Column names for MA order\n",
    "results_test.index = [\"Test MSE\", \"Test MAE\"]\n",
    "\n",
    "results_validate = pd.DataFrame(np.zeros((2, 24)))  # MSE and MAE for validation set\n",
    "results_validate.columns = [f\"q={q}\" for q in range(1, 25)]  # Column names for MA order\n",
    "results_validate.index = [\"Validation MSE\", \"Validation MAE\"]\n",
    "\n",
    "# Function to fit MA model and compute MSE and MAE\n",
    "def fit_ma(q, training_data, testing, validation):\n",
    "    # Fit MA model with (0, 0, q) order (AR=0, differencing=0, MA=q)\n",
    "    mod = sm.tsa.ARIMA(training_data['PM10_Combined_Trend_Residual'], order=(0, 0, q))\n",
    "    res = mod.fit()\n",
    "    \n",
    "    # One-step ahead forecast for the testing set\n",
    "    forecast_test = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # One-step ahead forecast for the validation set\n",
    "    forecast_validate = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # Calculate Mean Squared Error for the test set\n",
    "    mse_test = ((testing['PM10_Combined_Trend_Residual'].values[:1] - forecast_test.values) ** 2).mean()\n",
    "    \n",
    "    # Calculate Mean Squared Error for the validation set\n",
    "    mse_validate = ((validation['PM10_Combined_Trend_Residual'].values[:1] - forecast_validate.values) ** 2).mean()\n",
    "    \n",
    "    # Calculate Mean Absolute Error for the test set\n",
    "    mae_test = np.abs(testing['PM10_Combined_Trend_Residual'].values[:1] - forecast_test.values).mean()\n",
    "    \n",
    "    # Calculate Mean Absolute Error for the validation set\n",
    "    mae_validate = np.abs(validation['PM10_Combined_Trend_Residual'].values[:1] - forecast_validate.values).mean()\n",
    "    \n",
    "    return mse_test, mae_test, mse_validate, mae_validate\n",
    "\n",
    "# Use joblib's Parallel to run the fit_ma function in parallel for different q values\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_ma)(q, y, testing, validation) for q in range(1, 25))\n",
    "\n",
    "# Store the results in the DataFrame\n",
    "for idx, (mse_test, mae_test, mse_validate, mae_validate) in enumerate(results):\n",
    "    q_value = idx + 1\n",
    "    results_test.loc[\"Test MSE\", f\"q={q_value}\"] = mse_test\n",
    "    results_test.loc[\"Test MAE\", f\"q={q_value}\"] = mae_test\n",
    "    results_validate.loc[\"Validation MSE\", f\"q={q_value}\"] = mse_validate\n",
    "    results_validate.loc[\"Validation MAE\", f\"q={q_value}\"] = mae_validate\n",
    "\n",
    "# Combine the results into one DataFrame for better display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0, ignore_index=False)\n",
    "\n",
    "# Print the results in a more readable format\n",
    "print(final_results.to_string(index=True))  # Display the results in a tabular format\n",
    "\n",
    "\n",
    "#runtime 3m 20s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 67\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mse_test, mse_validate\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Use joblib's Parallel to run the fit_arma function in parallel for different p, q combinations\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Use joblib's Parallel to run the fit_arma function in parallel for different p, q combinations\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(delayed(fit_arma)(p, q, training, testing, validation) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m25\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m25\u001b[39m))\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Store the results in the DataFrame\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (mse_test, mse_validate) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Progrem\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Assuming 'y' is your DataFrame\n",
    "# Ensure the 'PM10_Combined_Trend_Residual' column is numeric\n",
    "y['PM10_Combined_Trend_Residual'] = pd.to_numeric(y['PM10_Combined_Trend_Residual'], errors='coerce')\n",
    "\n",
    "# Optionally, handle missing values (e.g., by filling or dropping)\n",
    "y = y.dropna(subset=['PM10_Combined_Trend_Residual'])  # Drop rows with NaN values in the relevant column\n",
    "# Or, if you prefer filling NaN values with the forward fill method:\n",
    "# y['PM10_Combined_Trend_Residual'] = y['PM10_Combined_Trend_Residual'].fillna(method='ffill')\n",
    "\n",
    "# Define the length of the dataset and split sizes\n",
    "n = len(y)  # Length of the DataFrame y\n",
    "train_size_initial = int(n * 0.7)  # 70% of the data for training\n",
    "test_size = int(n * 0.1)   # 10% of the data for testing\n",
    "validate_size = int(n * 0.1)  # 10% of the data for validation\n",
    "\n",
    "# Define results DataFrame to store MSE for test and validation sets separately\n",
    "results_test = pd.DataFrame(np.zeros((1, 576)))  # MSE for test set\n",
    "results_test.columns = [f\"p={p}_q={q}\" for p in range(1, 25) for q in range(1, 25)]  # Column names for ARMA orders\n",
    "\n",
    "results_validate = pd.DataFrame(np.zeros((1, 576)))  # MSE for validation set\n",
    "results_validate.columns = [f\"p={p}_q={q}\" for p in range(1, 25) for q in range(1, 25)]  # Column names for ARMA orders\n",
    "\n",
    "# Use the first 50% of the data for the initial training set (50% of the train_size)\n",
    "train_size_current = int(train_size_initial * 0.5)  # Initial 50% of the train set\n",
    "testing_start = train_size_current\n",
    "testing_end = testing_start + test_size\n",
    "\n",
    "# Expanding the training set by adding the next 10% in each iteration\n",
    "training = y[:train_size_current]  # Initial training set\n",
    "testing = y[testing_start:testing_end]  # Testing set\n",
    "validation_start = testing_end\n",
    "validation_end = validation_start + validate_size\n",
    "validation = y[validation_start:validation_end]  # Validation set\n",
    "\n",
    "# Function to fit ARMA model and compute MSE\n",
    "def fit_arma(p, q, training_data, testing, validation):\n",
    "    try:\n",
    "        # Fit ARMA model with (p, 0, q) order (AR=p, differencing=0, MA=q)\n",
    "        mod = sm.tsa.ARIMA(training_data['PM10_Combined_Trend_Residual'], order=(p, 0, q))\n",
    "        res = mod.fit()\n",
    "        \n",
    "        # One-step ahead forecast for the testing set\n",
    "        forecast_test = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "        \n",
    "        # One-step ahead forecast for the validation set\n",
    "        forecast_validate = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "        \n",
    "        # Calculate Mean Squared Error for the test set\n",
    "        mse_test = ((testing['PM10_Combined_Trend_Residual'].values[:1] - forecast_test.values) ** 2).mean()\n",
    "        \n",
    "        # Calculate Mean Squared Error for the validation set\n",
    "        mse_validate = ((validation['PM10_Combined_Trend_Residual'].values[:1] - forecast_validate.values) ** 2).mean()\n",
    "        \n",
    "    except np.linalg.LinAlgError:\n",
    "        mse_test = np.nan\n",
    "        mse_validate = np.nan\n",
    "    \n",
    "    return mse_test, mse_validate\n",
    "\n",
    "# Use joblib's Parallel to run the fit_arma function in parallel for different p, q combinations\n",
    "# Use joblib's Parallel to run the fit_arma function in parallel for different p, q combinations\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_arma)(p, q, training, testing, validation) for p in range(1, 25) for q in range(1, 25))\n",
    "\n",
    "# Store the results in the DataFrame\n",
    "for idx, (mse_test, mse_validate) in enumerate(results):\n",
    "    p_value = (idx // 24) + 1  # Calculate p from the index\n",
    "    q_value = (idx % 24) + 1   # Calculate q from the index\n",
    "    results_test.loc[0, f\"p={p_value}_q={q_value}\"] = mse_test\n",
    "    results_validate.loc[0, f\"p={p_value}_q={q_value}\"] = mse_validate\n",
    "\n",
    "# Combine the results into one DataFrame for better display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0, ignore_index=True)\n",
    "final_results.index = [\"Test MSE\", \"Validation MSE\"]\n",
    "\n",
    "# Print the results in a more readable format\n",
    "print(final_results.to_string(index=True))  # Display the results in a tabular format\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
