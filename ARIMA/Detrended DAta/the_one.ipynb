{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>PM10_Combined_Trend_Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>75.197962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>51.472071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>32.710483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>24.801767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>9.683660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datum  PM10_Combined_Trend_Residual\n",
       "0  2022-01-01 00:00:00+00:00                     75.197962\n",
       "1  2022-01-01 01:00:00+00:00                     51.472071\n",
       "2  2022-01-01 02:00:00+00:00                     32.710483\n",
       "3  2022-01-01 03:00:00+00:00                     24.801767\n",
       "4  2022-01-01 04:00:00+00:00                      9.683660"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "y = pd.read_csv('../Detrended DAta/TargetCutto50MostImpFeatures_DF.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set MSE:\n",
      "          1          2          3          4          5          6   \\\n",
      "0  83.520059  80.194799  82.802817  82.484601  82.148029  78.614943   \n",
      "\n",
      "          7          8          9          10  \n",
      "0  75.363332  73.478572  72.069796  70.744455  \n",
      "\n",
      "Validation Set MSE:\n",
      "          1          2          3          4          5          6   \\\n",
      "0  42.906973  40.533155  42.393327  42.165722  41.925179  39.412246   \n",
      "\n",
      "          7          8          9          10  \n",
      "0  37.119972  35.800774  34.819484  33.900142  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Assuming 'y' is your DataFrame\n",
    "# Ensure the 'PM10_Combined_Trend_Residual' column is numeric\n",
    "y['PM10_Combined_Trend_Residual'] = pd.to_numeric(y['PM10_Combined_Trend_Residual'], errors='coerce')\n",
    "\n",
    "# Optionally, handle missing values (e.g., by filling or dropping)\n",
    "y = y.dropna(subset=['PM10_Combined_Trend_Residual'])  # Drop rows with NaN values in the relevant column\n",
    "# Or, if you prefer filling NaN values with the forward fill method:\n",
    "# y['PM10_Combined_Trend_Residual'] = y['PM10_Combined_Trend_Residual'].fillna(method='ffill')\n",
    "\n",
    "# Define the length of the dataset and split sizes\n",
    "n = len(y)  # Length of the DataFrame y\n",
    "train_size_initial = int(n * 0.7)  # 70% of the data for training\n",
    "test_size = int(n * 0.1)   # 10% of the data for testing\n",
    "validate_size = int(n * 0.1)  # 10% of the data for validation\n",
    "\n",
    "# Define results DataFrame to store MSE for test and validation sets separately\n",
    "results_test = pd.DataFrame(np.zeros((1, 10)))  # MSE for test set\n",
    "results_test.columns = np.arange(1, 11)\n",
    "\n",
    "results_validate = pd.DataFrame(np.zeros((1, 10)))  # MSE for validation set\n",
    "results_validate.columns = np.arange(1, 11)\n",
    "\n",
    "# Use the first 50% of the data for the initial training set (50% of the train_size)\n",
    "train_size_current = int(train_size_initial * 0.5)  # Initial 50% of the train set\n",
    "testing_start = train_size_current\n",
    "testing_end = testing_start + test_size\n",
    "\n",
    "# Expanding the training set by adding the next 10% in each iteration\n",
    "training = y[:train_size_current]  # Initial training set\n",
    "testing = y[testing_start:testing_end]  # Testing set\n",
    "validation_start = testing_end\n",
    "validation_end = validation_start + validate_size\n",
    "validation = y[validation_start:validation_end]  # Validation set\n",
    "\n",
    "# Function to fit ARIMA model and compute MSE\n",
    "def fit_arima(p, training_data, testing, validation):\n",
    "    mod = sm.tsa.ARIMA(training_data['PM10_Combined_Trend_Residual'], order=(p, 0, 0))\n",
    "    res = mod.fit()\n",
    "    \n",
    "    # One-step ahead forecast for the testing set\n",
    "    forecast_test = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # One-step ahead forecast for the validation set\n",
    "    forecast_validate = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # Calculate Mean Squared Error for the test set\n",
    "    mse_test = ((testing['PM10_Combined_Trend_Residual'].values[:1] - forecast_test.values) ** 2).mean()\n",
    "    \n",
    "    # Calculate Mean Squared Error for the validation set\n",
    "    mse_validate = ((validation['PM10_Combined_Trend_Residual'].values[:1] - forecast_validate.values) ** 2).mean()\n",
    "    \n",
    "    return mse_test, mse_validate\n",
    "\n",
    "# Use joblib's Parallel to run the fit_arima function in parallel for different p values\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_arima)(p, y, testing, validation) for p in range(1, 11))\n",
    "\n",
    "# Store the results in the DataFrame\n",
    "for idx, (mse_test, mse_validate) in enumerate(results):\n",
    "    p_value = idx + 1\n",
    "    results_test.loc[0, p_value] = mse_test\n",
    "    results_validate.loc[0, p_value] = mse_validate\n",
    "\n",
    "# Print the results\n",
    "print(\"Test Set MSE:\")\n",
    "print(results_test)\n",
    "\n",
    "print(\"\\nValidation Set MSE:\")\n",
    "print(results_validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      q=1        q=2        q=3        q=4        q=5        q=6        q=7        q=8        q=9       q=10\n",
      "Test MSE        65.985091  67.075365  75.850070  68.614055  72.051681  77.651255  80.237003  85.623280  88.091847  90.037087\n",
      "Validation MSE  30.631036  31.375297  37.461807  32.430413  34.806893  38.730776  40.563161  44.418164  46.201061  47.612732\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Assuming 'y' is your DataFrame\n",
    "# Ensure the 'PM10_Combined_Trend_Residual' column is numeric\n",
    "y['PM10_Combined_Trend_Residual'] = pd.to_numeric(y['PM10_Combined_Trend_Residual'], errors='coerce')\n",
    "\n",
    "# Optionally, handle missing values (e.g., by filling or dropping)\n",
    "y = y.dropna(subset=['PM10_Combined_Trend_Residual'])  # Drop rows with NaN values in the relevant column\n",
    "# Or, if you prefer filling NaN values with the forward fill method:\n",
    "# y['PM10_Combined_Trend_Residual'] = y['PM10_Combined_Trend_Residual'].fillna(method='ffill')\n",
    "\n",
    "# Define the length of the dataset and split sizes\n",
    "n = len(y)  # Length of the DataFrame y\n",
    "train_size_initial = int(n * 0.7)  # 70% of the data for training\n",
    "test_size = int(n * 0.1)   # 10% of the data for testing\n",
    "validate_size = int(n * 0.1)  # 10% of the data for validation\n",
    "\n",
    "# Define results DataFrame to store MSE for test and validation sets separately\n",
    "results_test = pd.DataFrame(np.zeros((1, 10)))  # MSE for test set\n",
    "results_test.columns = [f\"q={q}\" for q in range(1, 11)]  # Column names for MA order\n",
    "\n",
    "results_validate = pd.DataFrame(np.zeros((1, 10)))  # MSE for validation set\n",
    "results_validate.columns = [f\"q={q}\" for q in range(1, 11)]  # Column names for MA order\n",
    "\n",
    "# Use the first 50% of the data for the initial training set (50% of the train_size)\n",
    "train_size_current = int(train_size_initial * 0.5)  # Initial 50% of the train set\n",
    "testing_start = train_size_current\n",
    "testing_end = testing_start + test_size\n",
    "\n",
    "# Expanding the training set by adding the next 10% in each iteration\n",
    "training = y[:train_size_current]  # Initial training set\n",
    "testing = y[testing_start:testing_end]  # Testing set\n",
    "validation_start = testing_end\n",
    "validation_end = validation_start + validate_size\n",
    "validation = y[validation_start:validation_end]  # Validation set\n",
    "\n",
    "# Function to fit MA model and compute MSE\n",
    "def fit_ma(q, training_data, testing, validation):\n",
    "    # Fit MA model with (0, 0, q) order (AR=0, differencing=0, MA=q)\n",
    "    mod = sm.tsa.ARIMA(training_data['PM10_Combined_Trend_Residual'], order=(0, 0, q))\n",
    "    res = mod.fit()\n",
    "    \n",
    "    # One-step ahead forecast for the testing set\n",
    "    forecast_test = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # One-step ahead forecast for the validation set\n",
    "    forecast_validate = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # Calculate Mean Squared Error for the test set\n",
    "    mse_test = ((testing['PM10_Combined_Trend_Residual'].values[:1] - forecast_test.values) ** 2).mean()\n",
    "    \n",
    "    # Calculate Mean Squared Error for the validation set\n",
    "    mse_validate = ((validation['PM10_Combined_Trend_Residual'].values[:1] - forecast_validate.values) ** 2).mean()\n",
    "    \n",
    "    return mse_test, mse_validate\n",
    "\n",
    "# Use joblib's Parallel to run the fit_ma function in parallel for different q values\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_ma)(q, y, testing, validation) for q in range(1, 11))\n",
    "\n",
    "# Store the results in the DataFrame\n",
    "for idx, (mse_test, mse_validate) in enumerate(results):\n",
    "    q_value = idx + 1\n",
    "    results_test.loc[0, f\"q={q_value}\"] = mse_test\n",
    "    results_validate.loc[0, f\"q={q_value}\"] = mse_validate\n",
    "\n",
    "# Combine the results into one DataFrame for better display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0, ignore_index=True)\n",
    "final_results.index = [\"Test MSE\", \"Validation MSE\"]\n",
    "\n",
    "# Print the results in a more readable format\n",
    "print(final_results.to_string(index=True))  # Display the results in a tabular format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Assuming 'y' is your DataFrame\n",
    "# Ensure the 'PM10_Combined_Trend_Residual' column is numeric\n",
    "y['PM10_Combined_Trend_Residual'] = pd.to_numeric(y['PM10_Combined_Trend_Residual'], errors='coerce')\n",
    "\n",
    "# Optionally, handle missing values (e.g., by filling or dropping)\n",
    "y = y.dropna(subset=['PM10_Combined_Trend_Residual'])  # Drop rows with NaN values in the relevant column\n",
    "# Or, if you prefer filling NaN values with the forward fill method:\n",
    "# y['PM10_Combined_Trend_Residual'] = y['PM10_Combined_Trend_Residual'].fillna(method='ffill')\n",
    "\n",
    "# Define the length of the dataset and split sizes\n",
    "n = len(y)  # Length of the DataFrame y\n",
    "train_size_initial = int(n * 0.7)  # 70% of the data for training\n",
    "test_size = int(n * 0.1)   # 10% of the data for testing\n",
    "validate_size = int(n * 0.1)  # 10% of the data for validation\n",
    "\n",
    "# Define results DataFrame to store MSE for test and validation sets separately\n",
    "results_test = pd.DataFrame(np.zeros((1, 100)))  # MSE for test set\n",
    "results_test.columns = [f\"p={p}_q={q}\" for p in range(1, 11) for q in range(1, 11)]  # Column names for ARMA orders\n",
    "\n",
    "results_validate = pd.DataFrame(np.zeros((1, 100)))  # MSE for validation set\n",
    "results_validate.columns = [f\"p={p}_q={q}\" for p in range(1, 11) for q in range(1, 11)]  # Column names for ARMA orders\n",
    "\n",
    "# Use the first 50% of the data for the initial training set (50% of the train_size)\n",
    "train_size_current = int(train_size_initial * 0.5)  # Initial 50% of the train set\n",
    "testing_start = train_size_current\n",
    "testing_end = testing_start + test_size\n",
    "\n",
    "# Expanding the training set by adding the next 10% in each iteration\n",
    "training = y[:train_size_current]  # Initial training set\n",
    "testing = y[testing_start:testing_end]  # Testing set\n",
    "validation_start = testing_end\n",
    "validation_end = validation_start + validate_size\n",
    "validation = y[validation_start:validation_end]  # Validation set\n",
    "\n",
    "# Function to fit ARMA model and compute MSE\n",
    "def fit_arma(p, q, training_data, testing, validation):\n",
    "    # Fit ARMA model with (p, 0, q) order (AR=p, differencing=0, MA=q)\n",
    "    mod = sm.tsa.ARIMA(training_data['PM10_Combined_Trend_Residual'], order=(p, 0, q))\n",
    "    res = mod.fit()\n",
    "    \n",
    "    # One-step ahead forecast for the testing set\n",
    "    forecast_test = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # One-step ahead forecast for the validation set\n",
    "    forecast_validate = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # Calculate Mean Squared Error for the test set\n",
    "    mse_test = ((testing['PM10_Combined_Trend_Residual'].values[:1] - forecast_test.values) ** 2).mean()\n",
    "    \n",
    "    # Calculate Mean Squared Error for the validation set\n",
    "    mse_validate = ((validation['PM10_Combined_Trend_Residual'].values[:1] - forecast_validate.values) ** 2).mean()\n",
    "    \n",
    "    return mse_test, mse_validate\n",
    "\n",
    "# Use joblib's Parallel to run the fit_arma function in parallel for different p, q combinations\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_arma)(p, q, y, testing, validation) for p in range(1, 11) for q in range(1, 11))\n",
    "\n",
    "# Store the results in the DataFrame\n",
    "for idx, (mse_test, mse_validate) in enumerate(results):\n",
    "    p_value = (idx // 10) + 1  # Calculate p from the index\n",
    "    q_value = (idx % 10) + 1   # Calculate q from the index\n",
    "    results_test.loc[0, f\"p={p_value}_q={q_value}\"] = mse_test\n",
    "    results_validate.loc[0, f\"p={p_value}_q={q_value}\"] = mse_validate\n",
    "\n",
    "# Combine the results into one DataFrame for better display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0, ignore_index=True)\n",
    "final_results.index = [\"Test MSE\", \"Validation MSE\"]\n",
    "\n",
    "# Print the results in a more readable format\n",
    "print(final_results.to_string(index=True))  # Display the results in a tabular format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'y' is your DataFrame\n",
    "# Ensure the 'PM10_Combined_Trend_Residual' column is numeric\n",
    "y['PM10_Combined_Trend_Residual'] = pd.to_numeric(y['PM10_Combined_Trend_Residual'], errors='coerce')\n",
    "\n",
    "# Optionally, handle missing values (e.g., by filling or dropping)\n",
    "y = y.dropna(subset=['PM10_Combined_Trend_Residual'])  # Drop rows with NaN values in the relevant column\n",
    "# Or, if you prefer filling NaN values with the forward fill method:\n",
    "# y['PM10_Combined_Trend_Residual'] = y['PM10_Combined_Trend_Residual'].fillna(method='ffill')\n",
    "\n",
    "# Define the length of the dataset and split sizes\n",
    "n = len(y)  # Length of the DataFrame y\n",
    "train_size_initial = int(n * 0.7)  # 70% of the data for training\n",
    "test_size = int(n * 0.1)   # 10% of the data for testing\n",
    "validate_size = int(n * 0.1)  # 10% of the data for validation\n",
    "\n",
    "# Define results DataFrame to store MSE for test and validation sets separately\n",
    "results_test = pd.DataFrame(np.zeros((1, 100)))  # MSE for test set\n",
    "results_test.columns = [f\"p={p}_q={q}_P={P}_Q={Q}_s={s}\" for p in range(1, 11) for q in range(1, 11) for P in range(0, 3) for Q in range(0, 3) for s in [24, 720]]\n",
    "\n",
    "results_validate = pd.DataFrame(np.zeros((1, 100)))  # MSE for validation set\n",
    "results_validate.columns = [f\"p={p}_q={q}_P={P}_Q={Q}_s={s}\" for p in range(1, 11) for q in range(1, 11) for P in range(0, 3) for Q in range(0, 3) for s in [24, 720]]\n",
    "\n",
    "# Use the first 50% of the data for the initial training set (50% of the train_size)\n",
    "train_size_current = int(train_size_initial * 0.5)  # Initial 50% of the train set\n",
    "testing_start = train_size_current\n",
    "testing_end = testing_start + test_size\n",
    "\n",
    "# Expanding the training set by adding the next 10% in each iteration\n",
    "training = y[:train_size_current]  # Initial training set\n",
    "testing = y[testing_start:testing_end]  # Testing set\n",
    "validation_start = testing_end\n",
    "validation_end = validation_start + validate_size\n",
    "validation = y[validation_start:validation_end]  # Validation set\n",
    "\n",
    "# Function to fit SARIMA model and compute MSE\n",
    "def fit_sarima(p, q, P, Q, s, training_data, testing, validation):\n",
    "    # Fit SARIMA model with seasonal order (P, D, Q, s)\n",
    "    seasonal_order = (P, 1, Q, s)  # D=1 for seasonal differencing\n",
    "    mod = sm.tsa.ARIMA(training_data['PM10_Combined_Trend_Residual'], order=(p, 1, q), seasonal_order=seasonal_order)\n",
    "    res = mod.fit()\n",
    "    \n",
    "    # One-step ahead forecast for the testing set\n",
    "    forecast_test = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # One-step ahead forecast for the validation set\n",
    "    forecast_validate = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # Calculate Mean Squared Error for the test set\n",
    "    mse_test = ((testing['PM10_Combined_Trend_Residual'].values[:1] - forecast_test.values) ** 2).mean()\n",
    "    \n",
    "    # Calculate Mean Squared Error for the validation set\n",
    "    mse_validate = ((validation['PM10_Combined_Trend_Residual'].values[:1] - forecast_validate.values) ** 2).mean()\n",
    "    \n",
    "    return mse_test, mse_validate\n",
    "\n",
    "# Use joblib's Parallel to run the fit_sarima function in parallel for different p, q, P, Q, and s combinations\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_sarima)(p, q, P, Q, s, y, testing, validation) \n",
    "                              for p in range(1, 11) \n",
    "                              for q in range(1, 11) \n",
    "                              for P in range(0, 3)  # Seasonal AR order\n",
    "                              for Q in range(0, 3)  # Seasonal MA order\n",
    "                              for s in [24, 720])   # Seasonal period (daily and monthly seasonality)\n",
    "\n",
    "# Store the results in the DataFrame\n",
    "for idx, (mse_test, mse_validate) in enumerate(results):\n",
    "    p_value = idx // 72 + 1  # Calculate p from the index\n",
    "    q_value = (idx % 72) // 24 + 1  # Calculate q from the index\n",
    "    P_value = (idx % 24) // 8  # Calculate P from the index\n",
    "    Q_value = (idx % 8) // 4  # Calculate Q from the index\n",
    "    s_value = [24, 720][idx % 2]  # Seasonal period (either 24 or 720)\n",
    "    results_test.loc[0, f\"p={p_value}_q={q_value}_P={P_value}_Q={Q_value}_s={s_value}\"] = mse_test\n",
    "    results_validate.loc[0, f\"p={p_value}_q={q_value}_P={P_value}_Q={Q_value}_s={s_value}\"] = mse_validate\n",
    "\n",
    "# Combine the results into one DataFrame for better display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0, ignore_index=True)\n",
    "final_results.index = [\"Test MSE\", \"Validation MSE\"]\n",
    "\n",
    "# Print the results in a more readable format\n",
    "print(final_results.to_string(index=True))  # Display the results in a tabular format\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
