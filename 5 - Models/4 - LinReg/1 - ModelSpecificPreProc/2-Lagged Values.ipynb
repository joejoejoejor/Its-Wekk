{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "features = pd.read_csv('../0 - ModelData/50MostImp+CombinedFeatures.csv')\n",
    "AllFeatures = pd.read_csv('../../../Fucking Final Data/Working_DataFrame.csv')\n",
    "target = pd.read_csv('../../../Fucking Final Data/CleanedFinal_Target_Data_Combined_resid_Trend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in features dataframe:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "NaN values in AllFeatures dataframe:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "NaN values in target dataframe:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in features dataframe\n",
    "features_nan_counts = features.isnull().sum()\n",
    "print(\"NaN values in features dataframe:\")\n",
    "print(features_nan_counts[features_nan_counts > 0])\n",
    "\n",
    "# Check for NaN values in AllFeatures dataframe\n",
    "AllFeatures_nan_counts = AllFeatures.isnull().sum()\n",
    "print(\"\\nNaN values in AllFeatures dataframe:\")\n",
    "print(AllFeatures_nan_counts[AllFeatures_nan_counts > 0])\n",
    "\n",
    "# Check for NaN values in target dataframe\n",
    "target_nan_counts = target.isnull().sum()\n",
    "print(\"\\nNaN values in target dataframe:\")\n",
    "print(target_nan_counts[target_nan_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Datum  PM10_Combined_Trend_Residual\n",
      "0  2022-01-01 00:00:00+00:00                           NaN\n",
      "1  2022-01-01 01:00:00+00:00                     53.126838\n",
      "2  2022-01-01 02:00:00+00:00                     36.328107\n",
      "3  2022-01-01 03:00:00+00:00                     24.801767\n",
      "4  2022-01-01 04:00:00+00:00                      9.683660\n"
     ]
    }
   ],
   "source": [
    "# Function to replace outliers using IQR with moving average\n",
    "def replace_outliers_with_moving_avg(df, column, window=3):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Calculate the moving average\n",
    "    df['moving_avg'] = df[column].rolling(window=window, center=True).mean()\n",
    "    \n",
    "    # Replace outliers with the moving average\n",
    "    df[column] = df.apply(lambda row: row['moving_avg'] if row[column] < lower_bound or row[column] > upper_bound else row[column], axis=1)\n",
    "    \n",
    "    # Drop the temporary moving average column\n",
    "    df.drop(columns=['moving_avg'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Replace outliers in the target dataset\n",
    "target = replace_outliers_with_moving_avg(target, 'PM10_Combined_Trend_Residual')\n",
    "\n",
    "# Ensure the features and target datasets are aligned\n",
    "features = features[features['Datum'].isin(target['Datum'])]\n",
    "target = target[target['Datum'].isin(features['Datum'])]\n",
    "AllFeatures = AllFeatures[AllFeatures['Datum'].isin(target['Datum'])]\n",
    "\n",
    "print(target.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Basel Temperature [2 m elevation corrected]',\n",
      "       'Basel Precipitation Total', 'Basel Wind Speed [10 m]',\n",
      "       'Basel Wind Direction [10 m]', 'Stromverbrauch', '350n_sumLief',\n",
      "       '350v_sumLW', '352v_sumPW', '352v_sumLief', '354n_sumLW', '402v_sumPW',\n",
      "       '402n_sumLief', '402n_sumLW', '403n_sumLW', '403v_sumPW', '403v_sumLW',\n",
      "       '405v_sumLief', '405v_sumLW', '406n_sumLW', '406v_sumLief',\n",
      "       '406v_sumLW', '408n_sumPW', '408n_sumLief', '408n_sumLW', '409v_sumLW',\n",
      "       '415v_sumLief', '415v_sumLW', '415n_sumLW', '417n_sumPW',\n",
      "       '417n_sumLief', '417n_sumLW', '419v_sumLW', '419n_sumPW',\n",
      "       '419n_sumLief', '420n_sumLief', '420n_sumLW', '420v_sumLW',\n",
      "       '653n_sumLW', '659v_sumLW', '659n_sumLief', '659n_sumLW', '660v_sumPW',\n",
      "       '660v_sumLW', '660n_sumPW', '660n_sumLW', '84111104n_sumLief',\n",
      "       '84111104v_sumLief', '84111108v_sumLief', 'Gasverbrauch', 'Traffic',\n",
      "       'Basel Temperature [2 m elevation corrected]_x_Basel Temperature [2 m elevation corrected]',\n",
      "       'Basel Temperature [2 m elevation corrected]_x_Basel Wind Speed [10 m]',\n",
      "       'Basel Temperature [2 m elevation corrected]_x_660n_sumPW',\n",
      "       'Basel Temperature [2 m elevation corrected]_x_Gasverbrauch',\n",
      "       'Basel Temperature [2 m elevation corrected]_x_Traffic',\n",
      "       'Basel Precipitation Total_x_Hour',\n",
      "       'Basel Wind Speed [10 m]_x_Basel Wind Speed [10 m]',\n",
      "       'Basel Wind Speed [10 m]_x_Basel Wind Direction [10 m]',\n",
      "       'Basel Wind Speed [10 m]_x_Gasverbrauch',\n",
      "       'Basel Wind Speed [10 m]_x_Hour',\n",
      "       'Basel Wind Direction [10 m]_x_Basel Wind Direction [10 m]',\n",
      "       'Basel Wind Direction [10 m]_x_Hour', '406v_sumLW_x_408n_sumLief',\n",
      "       '660n_sumPW_x_Gasverbrauch', 'Gasverbrauch_x_Gasverbrauch',\n",
      "       'Gasverbrauch_x_Hour', 'PM10_1h_lag', 'PM10_2h_lag', 'PM10_24h_lag'],\n",
      "      dtype='object')\n",
      "Index(['Rebgassechange', 'Clarahuuschange', 'Citychange', 'Storchenchange',\n",
      "       'Post Baselchange', 'Aeschenchange', 'Bahnhof SÃ¼dchange',\n",
      "       'Bad. Bahnhofchange', 'Europechange', 'Claramattechange',\n",
      "       ...\n",
      "       '84111108n_sumLW', '84111108v_sumPW', '84111108v_sumLief',\n",
      "       '84111108v_sumLW', 'Gasverbrauch', 'Hour', 'Traffic', 'PM10_1h_lag',\n",
      "       'PM10_2h_lag', 'PM10_24h_lag'],\n",
      "      dtype='object', length=153)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from traitlets import All\n",
    "\n",
    "# Create lagged target variables\n",
    "features['PM10_1h_lag'] = target['PM10_Combined_Trend_Residual'].shift(1)\n",
    "features['PM10_2h_lag'] = target['PM10_Combined_Trend_Residual'].shift(2)\n",
    "features['PM10_24h_lag'] = target['PM10_Combined_Trend_Residual'].shift(24)\n",
    "AllFeatures['PM10_1h_lag'] = target['PM10_Combined_Trend_Residual'].shift(1)\n",
    "AllFeatures['PM10_2h_lag'] = target['PM10_Combined_Trend_Residual'].shift(2)\n",
    "AllFeatures['PM10_24h_lag'] = target['PM10_Combined_Trend_Residual'].shift(24)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "features.dropna(inplace=True)\n",
    "AllFeatures.dropna(inplace=True)\n",
    "target = target[target['Datum'].isin(features['Datum'])]\n",
    "target = target[target['Datum'].isin(AllFeatures['Datum'])]\n",
    "\n",
    "features.drop(columns=['Datum'], inplace=True)\n",
    "AllFeatures.drop(columns=['Datum'], inplace=True)\n",
    "\n",
    "# Standardize the features dataset\n",
    "scaler = StandardScaler()\n",
    "features_scaled = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n",
    "AllFeatures_scaled = pd.DataFrame(scaler.fit_transform(AllFeatures), columns=AllFeatures.columns)\n",
    "\n",
    "# Ensure there are no NaN values in the target dataset\n",
    "target = target.dropna()\n",
    "\n",
    "print(features_scaled.columns)\n",
    "print(AllFeatures_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaled.to_csv('../0 - ModelData/FINAL:50MostImp+CombinationFeatures+Lagged.csv', index=False)\n",
    "AllFeatures_scaled.to_csv('../0 - ModelData/FINAL:AllFeatures+Lagged.csv', index=False)\n",
    "target.to_csv('../0 - ModelData/FINAL:Target---OutliersTreated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
