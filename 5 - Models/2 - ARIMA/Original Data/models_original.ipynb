{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>PM10_Combined_Trend_Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>75.197962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>51.472071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>32.710483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>24.801767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>9.683660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datum  PM10_Combined_Trend_Residual\n",
       "0  2022-01-01 00:00:00+00:00                     75.197962\n",
       "1  2022-01-01 01:00:00+00:00                     51.472071\n",
       "2  2022-01-01 02:00:00+00:00                     32.710483\n",
       "3  2022-01-01 03:00:00+00:00                     24.801767\n",
       "4  2022-01-01 04:00:00+00:00                      9.683660"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "y = pd.read_csv('../../../4 - Data/04_WorkingDatasets/NormalData/Target_Additive.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>PM10_Combined_Trend_Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>75.197962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>51.472071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>32.710483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>24.801767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>9.683660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datum  PM10_Combined_Trend_Residual\n",
       "0  2022-01-01 00:00:00+00:00                     75.197962\n",
       "1  2022-01-01 01:00:00+00:00                     51.472071\n",
       "2  2022-01-01 02:00:00+00:00                     32.710483\n",
       "3  2022-01-01 03:00:00+00:00                     24.801767\n",
       "4  2022-01-01 04:00:00+00:00                      9.683660"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_filtered = y[['Datum', 'PM10_Combined_Trend_Residual']]\n",
    "y_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Datum', 'PM10_Combined_Trend_Residual'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the column names to check the exact name of the 'Datum/ Zeit' column\n",
    "print(y.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Datum', 'PM10_Combined_Trend_Residual'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the column names to check for the correct timestamp column name\n",
    "print(y_filtered.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                p=1_q=1_P=0_Q=0_s=24  p=1_q=1_P=0_Q=1_s=24  p=1_q=1_P=1_Q=0_s=24  p=1_q=1_P=1_Q=1_s=24  p=1_q=2_P=0_Q=0_s=24  p=1_q=2_P=0_Q=1_s=24  p=1_q=2_P=1_Q=0_s=24  p=1_q=2_P=1_Q=1_s=24  p=1_q=3_P=0_Q=0_s=24  p=1_q=3_P=0_Q=1_s=24  p=1_q=3_P=1_Q=0_s=24  p=1_q=3_P=1_Q=1_s=24  p=2_q=1_P=0_Q=0_s=24  p=2_q=1_P=0_Q=1_s=24  p=2_q=1_P=1_Q=0_s=24  p=2_q=1_P=1_Q=1_s=24  p=2_q=2_P=0_Q=0_s=24  p=2_q=2_P=0_Q=1_s=24  p=2_q=2_P=1_Q=0_s=24  p=2_q=2_P=1_Q=1_s=24  p=2_q=3_P=0_Q=0_s=24  p=2_q=3_P=0_Q=1_s=24  p=2_q=3_P=1_Q=0_s=24  p=2_q=3_P=1_Q=1_s=24  p=3_q=1_P=0_Q=0_s=24  p=3_q=1_P=0_Q=1_s=24  p=3_q=1_P=1_Q=0_s=24  p=3_q=1_P=1_Q=1_s=24  p=3_q=2_P=0_Q=0_s=24  p=3_q=2_P=0_Q=1_s=24  p=3_q=2_P=1_Q=0_s=24  p=3_q=2_P=1_Q=1_s=24  p=3_q=3_P=0_Q=0_s=24  p=3_q=3_P=0_Q=1_s=24  p=3_q=3_P=1_Q=0_s=24  p=3_q=3_P=1_Q=1_s=24  p=1_q=1_P=2_Q=0_s=24  p=1_q=1_P=2_Q=1_s=24  p=1_q=2_P=2_Q=0_s=24  p=1_q=2_P=2_Q=1_s=24  p=1_q=3_P=2_Q=0_s=24  p=1_q=3_P=2_Q=1_s=24\n",
      "Test MSE                   36.172646             35.687380             36.025980             35.521034             36.034437             35.530498             35.925184             35.435084             35.925933             35.454369             35.942278             35.459847                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0             35.899932             35.417446             35.936647             35.332766             36.110055             35.620479\n",
      "Validation MSE              0.093577              0.119981              0.101194              0.129832              0.100746              0.129260              0.106610              0.135083              0.106569              0.133895              0.105681              0.133559                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0                   0.0              0.107990              0.136175              0.105987              0.141479              0.096789              0.123893\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Assuming 'y_filtered' is your DataFrame\n",
    "# Ensure the 'PM10 (Stundenmittelwerte)' column is numeric\n",
    "y_filtered['PM10_Combined_Trend_Residual'] = pd.to_numeric(y_filtered['PM10_Combined_Trend_Residual'], errors='coerce')\n",
    "\n",
    "# Optionally, handle missing values (e.g., by filling or dropping)\n",
    "y_filtered = y_filtered.dropna(subset=['PM10_Combined_Trend_Residual'])  # Drop rows with NaN values in the relevant column\n",
    "\n",
    "# Convert the 'Datum/Zeit' column to datetime format for proper time series handling\n",
    "y_filtered['Datum'] = pd.to_datetime(y_filtered['Datum'], errors='coerce')\n",
    "\n",
    "# Define the length of the dataset and split sizes\n",
    "n = len(y_filtered)  # Length of the DataFrame y_filtered\n",
    "train_size_initial = int(n * 0.7)  # 70% of the data for training\n",
    "test_size = int(n * 0.1)   # 10% of the data for testing\n",
    "validate_size = int(n * 0.1)  # 10% of the data for validation\n",
    "\n",
    "# Adjusting the number of combinations to avoid the mismatch\n",
    "# Generate a manageable number of columns (e.g., based on a subset of combinations)\n",
    "columns = [f\"p={p}_q={q}_P={P}_Q={Q}_s={s}\" \n",
    "           for p in range(1, 4)  # Limit to 3 values for p\n",
    "           for q in range(1, 4)  # Limit to 3 values for q\n",
    "           for P in range(0, 2)  # Limit to 2 values for P\n",
    "           for Q in range(0, 2)  # Limit to 2 values for Q\n",
    "           for s in [24]]        # Limit to 1 seasonal period (just 24)\n",
    "\n",
    "# Now assign the reduced list to the results DataFrame\n",
    "results_test = pd.DataFrame(np.zeros((1, len(columns))))  # Adjust to match the number of columns\n",
    "results_test.columns = columns\n",
    "\n",
    "results_validate = pd.DataFrame(np.zeros((1, len(columns))))  # Adjust to match the number of columns\n",
    "results_validate.columns = columns\n",
    "\n",
    "# Use the first 50% of the data for the initial training set (50% of the train_size)\n",
    "train_size_current = int(train_size_initial * 0.5)  # Initial 50% of the train set\n",
    "testing_start = train_size_current\n",
    "testing_end = testing_start + test_size\n",
    "\n",
    "# Expanding the training set by adding the next 10% in each iteration\n",
    "training = y_filtered[:train_size_current]  # Initial training set\n",
    "testing = y_filtered[testing_start:testing_end]  # Testing set\n",
    "validation_start = testing_end\n",
    "validation_end = validation_start + validate_size\n",
    "validation = y_filtered[validation_start:validation_end]  # Validation set\n",
    "\n",
    "# Function to fit SARIMA model and compute MSE\n",
    "def fit_sarima(p, q, P, Q, s, training_data, testing, validation):\n",
    "    # Fit SARIMA model with seasonal order (P, D, Q, s)\n",
    "    seasonal_order = (P, 1, Q, s)  # D=1 for seasonal differencing\n",
    "    mod = sm.tsa.ARIMA(training_data['PM10_Combined_Trend_Residual'], order=(p, 1, q), seasonal_order=seasonal_order)\n",
    "    res = mod.fit()\n",
    "    \n",
    "    # One-step ahead forecast for the testing set\n",
    "    forecast_test = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # One-step ahead forecast for the validation set\n",
    "    forecast_validate = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "    \n",
    "    # Calculate Mean Squared Error for the test set\n",
    "    mse_test = ((testing['PM10_Combined_Trend_Residual'].values[:1] - forecast_test) ** 2).mean()\n",
    "    \n",
    "    # Calculate Mean Squared Error for the validation set\n",
    "    mse_validate = ((validation['PM10_Combined_Trend_Residual'].values[:1] - forecast_validate) ** 2).mean()\n",
    "    \n",
    "    return mse_test, mse_validate\n",
    "\n",
    "# Use joblib's Parallel to run the fit_sarima function in parallel for different p, q, P, Q, and s combinations\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_sarima)(p, q, P, Q, s, y_filtered, testing, validation) \n",
    "                              for p in range(1, 4)  # Limit p to 3\n",
    "                              for q in range(1, 4)  # Limit q to 3\n",
    "                              for P in range(0, 2)  # Limit P to 2\n",
    "                              for Q in range(0, 2)  # Limit Q to 2\n",
    "                              for s in [24])       # Limit to one seasonal period (24)\n",
    "\n",
    "# Store the results in the DataFrame\n",
    "for idx, (mse_test, mse_validate) in enumerate(results):\n",
    "    p_value = idx // 36 + 1  # Calculate p from the index\n",
    "    q_value = (idx % 36) // 12 + 1  # Calculate q from the index\n",
    "    P_value = (idx % 12) // 4  # Calculate P from the index\n",
    "    Q_value = (idx % 4) // 2  # Calculate Q from the index\n",
    "    s_value = [24][idx % 1]  # Seasonal period (just 24)\n",
    "    results_test.loc[0, f\"p={p_value}_q={q_value}_P={P_value}_Q={Q_value}_s={s_value}\"] = mse_test\n",
    "    results_validate.loc[0, f\"p={p_value}_q={q_value}_P={P_value}_Q={Q_value}_s={s_value}\"] = mse_validate\n",
    "\n",
    "# Combine the results into one DataFrame for better display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0, ignore_index=True)\n",
    "final_results.index = [\"Test MSE\", \"Validation MSE\"]\n",
    "\n",
    "# Print the results in a more readable format\n",
    "print(final_results.to_string(index=True))  # Display the results in a tabular format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
