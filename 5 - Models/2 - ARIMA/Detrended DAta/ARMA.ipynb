{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>PM10_Combined_Trend_Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>75.197962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>51.472071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>32.710483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>24.801767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>9.683660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datum  PM10_Combined_Trend_Residual\n",
       "0  2022-01-01 00:00:00+00:00                     75.197962\n",
       "1  2022-01-01 01:00:00+00:00                     51.472071\n",
       "2  2022-01-01 02:00:00+00:00                     32.710483\n",
       "3  2022-01-01 03:00:00+00:00                     24.801767\n",
       "4  2022-01-01 04:00:00+00:00                      9.683660"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "y = pd.read_csv('../Detrended DAta/TargetCutto50MostImpFeatures_DF.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data\n",
    "def train_test_val_split(data, train_ratio=0.7, test_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Splits the dataset into Train, Test, and Validation sets.\n",
    "    Parameters:\n",
    "        data: DataFrame - The full dataset to split.\n",
    "        train_ratio: float - Proportion of data to use for training.\n",
    "        test_ratio: float - Proportion of data to use for testing.\n",
    "    Returns:\n",
    "        train_data, test_data, val_data - DataFrames for train, test, and validation splits.\n",
    "    \"\"\"\n",
    "    train_size = int(len(data) * train_ratio)\n",
    "    test_size = int(len(data) * test_ratio)\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:train_size + test_size]\n",
    "    val_data = data[train_size + test_size:]\n",
    "    return train_data, test_data, val_data\n",
    "\n",
    "# Call the function to split the data\n",
    "train_data, test_data, val_data = train_test_val_split(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       1          2          3          4          5          6          7          8          9          10         11         12         13         14         15         16         17         18         19         20         21         22         23         24\n",
      "Test MSE        75.799678  75.661107  75.658828  75.655298  75.642856  75.630336   75.61196   75.58474  75.552603  75.511302  75.443446  75.325239  75.187644  75.089311  75.000972  74.880268  74.773601  74.662847  74.555648  74.453701  74.369358   74.32279  74.298822  74.310638\n",
      "Test MAE         6.208841   6.196197   6.195977   6.195576   6.194229   6.192906   6.191131   6.188715   6.186147   6.183305   6.178492    6.17036   6.161023   6.154307   6.148161   6.139595   6.131692   6.122664   6.113185   6.102667    6.09146   6.082506   6.071415   6.062875\n",
      "Validation MSE  37.612108  37.414803  37.409042  37.398266  37.364463  37.330864  37.286039  37.225124  37.161295  37.092591  36.983614  36.812227   36.63508   36.51635  36.411075  36.263988  36.130033  35.981425  35.818324  35.622818  35.385169  35.164384  34.838952  34.527801\n",
      "Validation MAE   5.230892   5.215311   5.214837   5.213956   5.211148   5.208356     5.2046   5.199527   5.194261   5.188344   5.178446   5.161971   5.143804   5.130962   5.119271   5.102412   5.086728   5.069075   5.048858   5.024515   4.994648   4.967194   4.927441   4.891168\n"
     ]
    }
   ],
   "source": [
    "# Initialize Results DataFrames\n",
    "results_test = pd.DataFrame(index=[\"Test MSE\", \"Test MAE\"], columns=np.arange(1, 25))\n",
    "results_validate = pd.DataFrame(index=[\"Validation MSE\", \"Validation MAE\"], columns=np.arange(1, 25))\n",
    "\n",
    "# AR Model Fitting and Error Calculation\n",
    "def fit_ar_model(p, train_data, test_data, val_data):\n",
    "    try:\n",
    "        # Fit AR model\n",
    "        model = sm.tsa.ARIMA(train_data[\"PM10_Combined_Trend_Residual\"], order=(p, 0, 0))\n",
    "        res = model.fit()\n",
    "\n",
    "        # Forecast for test set\n",
    "        test_forecast = res.forecast(steps=len(test_data))\n",
    "        test_mse = ((test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values) ** 2).mean()\n",
    "        test_mae = np.abs(test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values).mean()\n",
    "\n",
    "        # Forecast for validation set\n",
    "        val_forecast = res.forecast(steps=len(val_data))\n",
    "        val_mse = ((val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values) ** 2).mean()\n",
    "        val_mae = np.abs(val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values).mean()\n",
    "\n",
    "        return test_mse, test_mae, val_mse, val_mae\n",
    "    except Exception as e:\n",
    "        print(f\"Error for p={p}: {e}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "# Run in parallel for AR lags (p) from 1 to 24\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_ar_model)(p, train_data, test_data, val_data) for p in range(1, 25))\n",
    "\n",
    "# Store results in DataFrames\n",
    "for idx, (test_mse, test_mae, val_mse, val_mae) in enumerate(results):\n",
    "    p_value = idx + 1\n",
    "    results_test.loc[\"Test MSE\", p_value] = test_mse\n",
    "    results_test.loc[\"Test MAE\", p_value] = test_mae\n",
    "    results_validate.loc[\"Validation MSE\", p_value] = val_mse\n",
    "    results_validate.loc[\"Validation MAE\", p_value] = val_mae\n",
    "\n",
    "# Combine results into a single DataFrame for display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0)\n",
    "print(final_results.to_string(index=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MA Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Run in parallel for MA lags (q) from 1 to 24\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(delayed(fit_ma_model)(q, train_data, test_data, val_data) \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m25\u001b[39m))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Store results in DataFrames\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (test_mse, test_mae, val_mse, val_mae) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "File \u001b[1;32mc:\\Users\\nando\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\nando\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nando\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize Results DataFrames\n",
    "results_test = pd.DataFrame(index=[\"Test MSE\", \"Test MAE\"], columns=np.arange(1, 25))\n",
    "results_validate = pd.DataFrame(index=[\"Validation MSE\", \"Validation MAE\"], columns=np.arange(1, 25))\n",
    "\n",
    "# MA Model Fitting and Error Calculation\n",
    "def fit_ma_model(q, train_data, test_data, val_data):\n",
    "    try:\n",
    "        # Fit MA model\n",
    "        model = sm.tsa.ARIMA(train_data[\"PM10_Combined_Trend_Residual\"], order=(0, 0, q))\n",
    "        res = model.fit()\n",
    "\n",
    "        # Forecast for test set\n",
    "        test_forecast = res.forecast(steps=len(test_data))\n",
    "        test_mse = ((test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values) ** 2).mean()\n",
    "        test_mae = np.abs(test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values).mean()\n",
    "\n",
    "        # Forecast for validation set\n",
    "        val_forecast = res.forecast(steps=len(val_data))\n",
    "        val_mse = ((val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values) ** 2).mean()\n",
    "        val_mae = np.abs(val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values).mean()\n",
    "\n",
    "        return test_mse, test_mae, val_mse, val_mae\n",
    "    except Exception as e:\n",
    "        print(f\"Error for q={q}: {e}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "# Run in parallel for MA lags (q) from 1 to 24\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_ma_model)(q, train_data, test_data, val_data) for q in range(1, 25))\n",
    "\n",
    "# Store results in DataFrames\n",
    "for idx, (test_mse, test_mae, val_mse, val_mae) in enumerate(results):\n",
    "    q_value = idx + 1\n",
    "    results_test.loc[\"Test MSE\", q_value] = test_mse\n",
    "    results_test.loc[\"Test MAE\", q_value] = test_mae\n",
    "    results_validate.loc[\"Validation MSE\", q_value] = val_mse\n",
    "    results_validate.loc[\"Validation MAE\", q_value] = val_mae\n",
    "\n",
    "# Combine results into a single DataFrame for display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0)\n",
    "print(final_results.to_string(index=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARMA model für mein laptop aktuell nur mit p und q bis 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 67\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mse_test, mse_validate\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Use joblib's Parallel to run the fit_arma function in parallel for different p, q combinations\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Use joblib's Parallel to run the fit_arma function in parallel for different p, q combinations\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(delayed(fit_arma)(p, q, training, testing, validation) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m25\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m25\u001b[39m))\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Store the results in the DataFrame\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (mse_test, mse_validate) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "File \u001b[1;32mc:\\Users\\nando\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\nando\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nando\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize Results DataFrames\n",
    "results_test = pd.DataFrame(index=[\"Test MSE\", \"Test MAE\"], columns=[(p, q) for p in range(1, 6) for q in range(1, 6)])\n",
    "results_validate = pd.DataFrame(index=[\"Validation MSE\", \"Validation MAE\"], columns=[(p, q) for p in range(1, 6) for q in range(1, 6)])\n",
    "\n",
    "# ARMA Model Fitting and Error Calculation\n",
    "def fit_arma_model(p, q, train_data, test_data, val_data):\n",
    "    try:\n",
    "        # Fit ARMA model\n",
    "        model = sm.tsa.ARIMA(train_data[\"PM10_Combined_Trend_Residual\"], order=(p, 0, q))\n",
    "        res = model.fit()\n",
    "\n",
    "        # Forecast for test set\n",
    "        test_forecast = res.forecast(steps=len(test_data))\n",
    "        test_mse = ((test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values) ** 2).mean()\n",
    "        test_mae = np.abs(test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values).mean()\n",
    "\n",
    "        # Forecast for validation set\n",
    "        val_forecast = res.forecast(steps=len(val_data))\n",
    "        val_mse = ((val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values) ** 2).mean()\n",
    "        val_mae = np.abs(val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values).mean()\n",
    "\n",
    "        return test_mse, test_mae, val_mse, val_mae\n",
    "    except Exception as e:\n",
    "        print(f\"Error for (p, q)=({p}, {q}): {e}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "# Run in parallel for ARMA combinations (p, q) from (1, 1) to (5, 5)\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(fit_arma_model)(p, q, train_data, test_data, val_data) \n",
    "    for p in range(1, 6) for q in range(1, 6)\n",
    ")\n",
    "\n",
    "# Store results in DataFrames\n",
    "for idx, (test_mse, test_mae, val_mse, val_mae) in enumerate(results):\n",
    "    p, q = results_test.columns[idx]\n",
    "    results_test.loc[\"Test MSE\", (p, q)] = test_mse\n",
    "    results_test.loc[\"Test MAE\", (p, q)] = test_mae\n",
    "    results_validate.loc[\"Validation MSE\", (p, q)] = val_mse\n",
    "    results_validate.loc[\"Validation MAE\", (p, q)] = val_mae\n",
    "\n",
    "# Combine results into a single DataFrame for display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0)\n",
    "print(final_results.to_string(index=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
