{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>PM10_Combined_Trend_Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>75.197962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>51.472071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>32.710483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>24.801767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>9.683660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datum  PM10_Combined_Trend_Residual\n",
       "0  2022-01-01 00:00:00+00:00                     75.197962\n",
       "1  2022-01-01 01:00:00+00:00                     51.472071\n",
       "2  2022-01-01 02:00:00+00:00                     32.710483\n",
       "3  2022-01-01 03:00:00+00:00                     24.801767\n",
       "4  2022-01-01 04:00:00+00:00                      9.683660"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "y = pd.read_csv('../../../4 - Data/04_WorkingDatasets/NormalData/Target_Additive.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data\n",
    "def train_test_val_split(data, train_ratio=0.7, test_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Splits the dataset into Train, Test, and Validation sets.\n",
    "    Parameters:\n",
    "        data: DataFrame - The full dataset to split.\n",
    "        train_ratio: float - Proportion of data to use for training.\n",
    "        test_ratio: float - Proportion of data to use for testing.\n",
    "    Returns:\n",
    "        train_data, test_data, val_data - DataFrames for train, test, and validation splits.\n",
    "    \"\"\"\n",
    "    train_size = int(len(data) * train_ratio)\n",
    "    test_size = int(len(data) * test_ratio)\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:train_size + test_size]\n",
    "    val_data = data[train_size + test_size:]\n",
    "    return train_data, test_data, val_data\n",
    "\n",
    "# Call the function to split the data\n",
    "train_data, test_data, val_data = train_test_val_split(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       1          2          3          4          5          6          7          8          9          10         11         12         13         14         15         16         17         18         19         20         21         22         23         24\n",
      "Test MSE        32.333164  33.813367  31.666185  30.175980  28.198729  27.776413  29.569121  30.791353  30.886824  30.808125  31.880366  31.588098  35.090431  37.467525  38.528550  38.441295  40.060341  43.162263  43.312247  45.811020  46.954571  48.026541  45.545261  43.777328\n",
      "Test MAE         5.686226   5.814926   5.627272   5.493267   5.310248   5.270333   5.437750   5.548996   5.557592   5.550507   5.646270   5.620329   5.923718   6.121072   6.207137   6.200104   6.329324   6.569799   6.581204   6.768384   6.852341   6.930118   6.748723   6.616444\n",
      "Validation MSE   0.402017   0.255377   0.480253   0.683941   1.020154   1.102376   0.778849   0.594870   0.581685   0.592542   0.454281   0.489923   0.157257   0.039681   0.012800   0.014441   0.000082   0.062263   0.068084   0.200802   0.283095   0.371910   0.183568   0.087716\n",
      "Validation MAE   0.634048   0.505348   0.693003   0.827007   1.010027   1.049941   0.882524   0.771278   0.762683   0.769767   0.674004   0.699945   0.396556   0.199202   0.113137   0.120170   0.009050   0.249525   0.260930   0.448110   0.532066   0.609844   0.428449   0.296170\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> ee4e503d5849336f46c11a5724c2d7a40b17aa2b
   "source": [
    "# Initialize Results DataFrames\n",
    "results_test = pd.DataFrame(index=[\"Test MSE\", \"Test MAE\"], columns=np.arange(1, 25))\n",
    "results_validate = pd.DataFrame(index=[\"Validation MSE\", \"Validation MAE\"], columns=np.arange(1, 25))\n",
    "\n",
    "# AR Model Fitting and Error Calculation\n",
    "def fit_ar_model(p, train_data, test_data, val_data):\n",
    "    try:\n",
    "        # Fit AR model\n",
    "        model = sm.tsa.ARIMA(train_data[\"PM10_Combined_Trend_Residual\"], order=(p, 0, 0))\n",
    "        res = model.fit()\n",
    "\n",
    "        # Forecast for test set\n",
    "        test_forecast = res.forecast(steps=len(test_data))\n",
    "        test_mse = ((test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values) ** 2).mean()\n",
    "        test_mae = np.abs(test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values).mean()\n",
    "\n",
    "        # Forecast for validation set\n",
    "        val_forecast = res.forecast(steps=len(val_data))\n",
    "        val_mse = ((val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values) ** 2).mean()\n",
    "        val_mae = np.abs(val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values).mean()\n",
    "\n",
    "        return test_mse, test_mae, val_mse, val_mae\n",
    "    except Exception as e:\n",
    "        print(f\"Error for p={p}: {e}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "# Run in parallel for AR lags (p) from 1 to 24\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_ar_model)(p, train_data, test_data, val_data) for p in range(1, 25))\n",
    "\n",
    "# Store results in DataFrames\n",
    "for idx, (test_mse, test_mae, val_mse, val_mae) in enumerate(results):\n",
    "    p_value = idx + 1\n",
    "    results_test.loc[\"Test MSE\", p_value] = test_mse\n",
    "    results_test.loc[\"Test MAE\", p_value] = test_mae\n",
    "    results_validate.loc[\"Validation MSE\", p_value] = val_mse\n",
    "    results_validate.loc[\"Validation MAE\", p_value] = val_mae\n",
    "\n",
    "# Combine results into a single DataFrame for display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0)\n",
    "print(final_results.to_string(index=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MA Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      q=1        q=2        q=3        q=4        q=5        q=6        q=7        q=8        q=9       q=10       q=11       q=12       q=13       q=14       q=15       q=16       q=17       q=18       q=19       q=20       q=21       q=22       q=23       q=24\n",
      "Test MSE        44.707372  37.215669  36.005321  38.464965  45.940007  43.065336  36.992701  34.349146  35.044508  33.367175  34.268274  34.200970  32.976066  31.726861  31.890131  32.595885  30.728016  31.265907  30.302858  29.911871  29.440349  30.937659  32.840429  36.720196\n",
      "Test MAE         6.686357   6.100465   6.000443   6.202013   6.777906   6.562418   6.082163   5.860814   5.919840   5.776433   5.853911   5.848160   5.742479   5.632660   5.647135   5.709281   5.543286   5.591593   5.504803   5.469175   5.425896   5.562163   5.730657   6.059719\n",
      "Validation MSE   0.134017   0.048316   0.102292   0.013986   0.209427   0.058634   0.056697   0.211103   0.160347   0.295763   0.217495   0.222892   0.333847   0.472813   0.453117   0.373313   0.603711   0.530977   0.664993   0.724370   0.799912   0.574732   0.347648   0.067889\n",
      "Validation MAE   0.366083   0.219809   0.319831   0.118261   0.457632   0.242144   0.238112   0.459460   0.400434   0.543841   0.466363   0.472115   0.577795   0.687614   0.673139   0.610994   0.776988   0.728682   0.815471   0.851099   0.894378   0.758111   0.589617   0.260555\n"
     ]
    }
   ],
   "source": [
    "# Initialize Results DataFrames\n",
    "results_test = pd.DataFrame(index=[\"Test MSE\", \"Test MAE\"], columns=np.arange(1, 25))\n",
    "results_validate = pd.DataFrame(index=[\"Validation MSE\", \"Validation MAE\"], columns=np.arange(1, 25))\n",
    "\n",
    "# MA Model Fitting and Error Calculation\n",
    "def fit_ma_model(q, train_data, test_data, val_data):\n",
    "    try:\n",
    "        # Fit MA model\n",
    "        model = sm.tsa.ARIMA(train_data[\"PM10_Combined_Trend_Residual\"], order=(0, 0, q))\n",
    "        res = model.fit()\n",
    "\n",
    "        # Forecast for test set\n",
    "        test_forecast = res.forecast(steps=len(test_data))\n",
    "        test_mse = ((test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values) ** 2).mean()\n",
    "        test_mae = np.abs(test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values).mean()\n",
    "\n",
    "        # Forecast for validation set\n",
    "        val_forecast = res.forecast(steps=len(val_data))\n",
    "        val_mse = ((val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values) ** 2).mean()\n",
    "        val_mae = np.abs(val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values).mean()\n",
    "\n",
    "        return test_mse, test_mae, val_mse, val_mae\n",
    "    except Exception as e:\n",
    "        print(f\"Error for q={q}: {e}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "# Run in parallel for MA lags (q) from 1 to 24\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_ma_model)(q, train_data, test_data, val_data) for q in range(1, 25))\n",
    "\n",
    "# Store results in DataFrames\n",
    "for idx, (test_mse, test_mae, val_mse, val_mae) in enumerate(results):\n",
    "    q_value = idx + 1\n",
    "    results_test.loc[\"Test MSE\", q_value] = test_mse\n",
    "    results_test.loc[\"Test MAE\", q_value] = test_mae\n",
    "    results_validate.loc[\"Validation MSE\", q_value] = val_mse\n",
    "    results_validate.loc[\"Validation MAE\", q_value] = val_mae\n",
    "\n",
    "# Combine results into a single DataFrame for display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0)\n",
    "print(final_results.to_string(index=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARMA model für mein laptop aktuell nur mit p und q bis 5"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": null,
>>>>>>> ee4e503d5849336f46c11a5724c2d7a40b17aa2b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  p=1_q=1    p=1_q=2    p=1_q=3    p=1_q=4    p=1_q=5    p=1_q=6    p=1_q=7    p=1_q=8    p=1_q=9   p=1_q=10   p=1_q=11   p=1_q=12   p=1_q=13   p=1_q=14   p=1_q=15   p=1_q=16   p=1_q=17   p=1_q=18   p=1_q=19   p=1_q=20   p=1_q=21   p=1_q=22   p=1_q=23   p=1_q=24    p=2_q=1    p=2_q=2    p=2_q=3    p=2_q=4    p=2_q=5    p=2_q=6    p=2_q=7    p=2_q=8    p=2_q=9   p=2_q=10   p=2_q=11   p=2_q=12   p=2_q=13   p=2_q=14   p=2_q=15   p=2_q=16   p=2_q=17   p=2_q=18   p=2_q=19   p=2_q=20   p=2_q=21   p=2_q=22   p=2_q=23   p=2_q=24    p=3_q=1    p=3_q=2    p=3_q=3    p=3_q=4    p=3_q=5    p=3_q=6    p=3_q=7    p=3_q=8    p=3_q=9   p=3_q=10   p=3_q=11   p=3_q=12   p=3_q=13   p=3_q=14   p=3_q=15   p=3_q=16   p=3_q=17   p=3_q=18   p=3_q=19   p=3_q=20   p=3_q=21   p=3_q=22   p=3_q=23   p=3_q=24    p=4_q=1    p=4_q=2    p=4_q=3    p=4_q=4   p=4_q=5    p=4_q=6    p=4_q=7    p=4_q=8    p=4_q=9   p=4_q=10   p=4_q=11   p=4_q=12   p=4_q=13   p=4_q=14   p=4_q=15   p=4_q=16   p=4_q=17   p=4_q=18   p=4_q=19   p=4_q=20   p=4_q=21  p=4_q=22   p=4_q=23   p=4_q=24    p=5_q=1    p=5_q=2    p=5_q=3    p=5_q=4    p=5_q=5    p=5_q=6    p=5_q=7    p=5_q=8    p=5_q=9   p=5_q=10   p=5_q=11   p=5_q=12   p=5_q=13   p=5_q=14   p=5_q=15   p=5_q=16   p=5_q=17   p=5_q=18   p=5_q=19   p=5_q=20   p=5_q=21   p=5_q=22  p=5_q=23   p=5_q=24    p=6_q=1    p=6_q=2    p=6_q=3    p=6_q=4    p=6_q=5    p=6_q=6    p=6_q=7    p=6_q=8    p=6_q=9   p=6_q=10   p=6_q=11   p=6_q=12   p=6_q=13   p=6_q=14   p=6_q=15   p=6_q=16   p=6_q=17   p=6_q=18   p=6_q=19   p=6_q=20   p=6_q=21   p=6_q=22   p=6_q=23   p=6_q=24    p=7_q=1    p=7_q=2    p=7_q=3    p=7_q=4    p=7_q=5    p=7_q=6    p=7_q=7    p=7_q=8    p=7_q=9   p=7_q=10   p=7_q=11   p=7_q=12   p=7_q=13   p=7_q=14   p=7_q=15   p=7_q=16   p=7_q=17   p=7_q=18   p=7_q=19   p=7_q=20   p=7_q=21   p=7_q=22   p=7_q=23   p=7_q=24    p=8_q=1    p=8_q=2    p=8_q=3    p=8_q=4    p=8_q=5    p=8_q=6    p=8_q=7    p=8_q=8    p=8_q=9   p=8_q=10   p=8_q=11   p=8_q=12   p=8_q=13   p=8_q=14   p=8_q=15   p=8_q=16   p=8_q=17   p=8_q=18   p=8_q=19   p=8_q=20   p=8_q=21   p=8_q=22   p=8_q=23   p=8_q=24    p=9_q=1    p=9_q=2    p=9_q=3    p=9_q=4    p=9_q=5    p=9_q=6    p=9_q=7    p=9_q=8    p=9_q=9   p=9_q=10   p=9_q=11   p=9_q=12   p=9_q=13   p=9_q=14   p=9_q=15   p=9_q=16   p=9_q=17   p=9_q=18   p=9_q=19   p=9_q=20   p=9_q=21   p=9_q=22   p=9_q=23   p=9_q=24   p=10_q=1   p=10_q=2   p=10_q=3   p=10_q=4   p=10_q=5   p=10_q=6   p=10_q=7   p=10_q=8   p=10_q=9  p=10_q=10  p=10_q=11  p=10_q=12  p=10_q=13  p=10_q=14  p=10_q=15  p=10_q=16  p=10_q=17  p=10_q=18  p=10_q=19  p=10_q=20  p=10_q=21  p=10_q=22  p=10_q=23  p=10_q=24   p=11_q=1   p=11_q=2   p=11_q=3   p=11_q=4   p=11_q=5   p=11_q=6   p=11_q=7   p=11_q=8   p=11_q=9  p=11_q=10  p=11_q=11  p=11_q=12  p=11_q=13  p=11_q=14  p=11_q=15  p=11_q=16  p=11_q=17  p=11_q=18  p=11_q=19  p=11_q=20  p=11_q=21  p=11_q=22  p=11_q=23  p=11_q=24   p=12_q=1   p=12_q=2   p=12_q=3   p=12_q=4   p=12_q=5   p=12_q=6   p=12_q=7   p=12_q=8   p=12_q=9  p=12_q=10  p=12_q=11  p=12_q=12  p=12_q=13  p=12_q=14  p=12_q=15  p=12_q=16  p=12_q=17  p=12_q=18  p=12_q=19  p=12_q=20  p=12_q=21  p=12_q=22  p=12_q=23  p=12_q=24   p=13_q=1   p=13_q=2   p=13_q=3   p=13_q=4   p=13_q=5   p=13_q=6   p=13_q=7   p=13_q=8   p=13_q=9  p=13_q=10  p=13_q=11  p=13_q=12  p=13_q=13  p=13_q=14  p=13_q=15  p=13_q=16  p=13_q=17  p=13_q=18  p=13_q=19  p=13_q=20  p=13_q=21  p=13_q=22  p=13_q=23  p=13_q=24   p=14_q=1   p=14_q=2   p=14_q=3   p=14_q=4   p=14_q=5   p=14_q=6   p=14_q=7   p=14_q=8   p=14_q=9  p=14_q=10  p=14_q=11  p=14_q=12  p=14_q=13  p=14_q=14  p=14_q=15  p=14_q=16  p=14_q=17  p=14_q=18  p=14_q=19  p=14_q=20  p=14_q=21  p=14_q=22  p=14_q=23  p=14_q=24   p=15_q=1   p=15_q=2   p=15_q=3   p=15_q=4   p=15_q=5   p=15_q=6   p=15_q=7   p=15_q=8   p=15_q=9  p=15_q=10  p=15_q=11  p=15_q=12  p=15_q=13  p=15_q=14  p=15_q=15  p=15_q=16  p=15_q=17  p=15_q=18  p=15_q=19  p=15_q=20  p=15_q=21  p=15_q=22  p=15_q=23  p=15_q=24   p=16_q=1   p=16_q=2   p=16_q=3   p=16_q=4   p=16_q=5   p=16_q=6   p=16_q=7   p=16_q=8   p=16_q=9  p=16_q=10  p=16_q=11  p=16_q=12  p=16_q=13  p=16_q=14  p=16_q=15  p=16_q=16  p=16_q=17  p=16_q=18  p=16_q=19  p=16_q=20  p=16_q=21  p=16_q=22  p=16_q=23  p=16_q=24   p=17_q=1   p=17_q=2   p=17_q=3   p=17_q=4   p=17_q=5   p=17_q=6   p=17_q=7   p=17_q=8   p=17_q=9  p=17_q=10  p=17_q=11  p=17_q=12  p=17_q=13  p=17_q=14  p=17_q=15  p=17_q=16  p=17_q=17  p=17_q=18  p=17_q=19  p=17_q=20  p=17_q=21  p=17_q=22  p=17_q=23  p=17_q=24   p=18_q=1   p=18_q=2   p=18_q=3   p=18_q=4   p=18_q=5   p=18_q=6   p=18_q=7   p=18_q=8   p=18_q=9  p=18_q=10  p=18_q=11  p=18_q=12  p=18_q=13  p=18_q=14  p=18_q=15  p=18_q=16  p=18_q=17  p=18_q=18  p=18_q=19  p=18_q=20  p=18_q=21  p=18_q=22  p=18_q=23  p=18_q=24   p=19_q=1   p=19_q=2   p=19_q=3   p=19_q=4   p=19_q=5   p=19_q=6   p=19_q=7   p=19_q=8   p=19_q=9  p=19_q=10  p=19_q=11  p=19_q=12  p=19_q=13  p=19_q=14  p=19_q=15  p=19_q=16  p=19_q=17  p=19_q=18  p=19_q=19  p=19_q=20  p=19_q=21  p=19_q=22  p=19_q=23  p=19_q=24   p=20_q=1   p=20_q=2   p=20_q=3   p=20_q=4   p=20_q=5   p=20_q=6   p=20_q=7   p=20_q=8   p=20_q=9  p=20_q=10  p=20_q=11  p=20_q=12  p=20_q=13  p=20_q=14  p=20_q=15  p=20_q=16  p=20_q=17  p=20_q=18  p=20_q=19  p=20_q=20  p=20_q=21  p=20_q=22  p=20_q=23  p=20_q=24   p=21_q=1   p=21_q=2   p=21_q=3   p=21_q=4   p=21_q=5   p=21_q=6   p=21_q=7   p=21_q=8   p=21_q=9  p=21_q=10  p=21_q=11  p=21_q=12  p=21_q=13  p=21_q=14  p=21_q=15  p=21_q=16  p=21_q=17  p=21_q=18  p=21_q=19  p=21_q=20  p=21_q=21  p=21_q=22  p=21_q=23  p=21_q=24   p=22_q=1   p=22_q=2   p=22_q=3   p=22_q=4   p=22_q=5   p=22_q=6   p=22_q=7  p=22_q=8   p=22_q=9  p=22_q=10  p=22_q=11  p=22_q=12  p=22_q=13  p=22_q=14  p=22_q=15  p=22_q=16  p=22_q=17  p=22_q=18  p=22_q=19  p=22_q=20  p=22_q=21  p=22_q=22  p=22_q=23  p=22_q=24   p=23_q=1   p=23_q=2   p=23_q=3   p=23_q=4   p=23_q=5   p=23_q=6   p=23_q=7   p=23_q=8   p=23_q=9  p=23_q=10  p=23_q=11  p=23_q=12  p=23_q=13  p=23_q=14  p=23_q=15  p=23_q=16  p=23_q=17  p=23_q=18  p=23_q=19  p=23_q=20  p=23_q=21  p=23_q=22  p=23_q=23  p=23_q=24   p=24_q=1   p=24_q=2   p=24_q=3   p=24_q=4   p=24_q=5   p=24_q=6   p=24_q=7   p=24_q=8   p=24_q=9  p=24_q=10  p=24_q=11  p=24_q=12  p=24_q=13  p=24_q=14  p=24_q=15  p=24_q=16  p=24_q=17  p=24_q=18  p=24_q=19  p=24_q=20  p=24_q=21  p=24_q=22  p=24_q=23  p=24_q=24\n",
      "Test MSE         0.041544   0.044469   0.033034   0.006354   0.003422   0.057594   0.050635   0.052988   0.068316   0.058529   0.056883   0.101066   0.257299   0.454687   0.471634   0.661856   0.618488   0.594204   0.588509   0.534575   0.572711   0.575075   0.764638   0.878149   0.036925   0.035345   0.030415   0.044618   0.000604   0.064602   0.061715   0.051388   0.060171   0.067217   0.060661   0.055076   0.061575   0.223597   0.457443   1.078040   0.832794   0.566241   0.583202   0.519377   0.574870   0.578358   0.867014   0.949062   0.081354   0.031178   0.029509   0.024776   0.041349   0.018979   0.003535   0.040528   0.051801   0.070420   0.062968   0.066259   0.049846   0.467463   0.286384   0.798186   0.853029   0.977834   1.150581   0.509199   0.659413   0.855382   0.648011   0.776735   0.049596   0.030737   0.044039   0.022439   0.04599   0.036227   0.049233   0.111028   0.024532   0.053689   0.061951   0.069355   0.072278   0.069095   1.108240   0.801619   0.774144   0.795674   1.031167   0.868907   0.669581   1.14867   0.653973   0.791655   0.045067   0.024407   0.000023   0.032250   0.004319   0.060430   0.047891   0.091620   0.053013   0.024476   0.037978   0.047222   0.069251   0.067910   0.360188   0.820371   0.720360   0.639694   0.714450   0.581173   0.448413   0.456634   0.48233   0.596805   0.065777   0.047101   0.073517   0.019047   0.060437   0.026494   0.042516   0.049309   0.047810   0.054905   0.069125   0.079376   0.102422   0.079753   0.461719   0.885780   0.860727   0.797939   0.673856   0.874604   0.438402   0.544171   0.460273   0.463667   0.152280   0.075155   0.057894   0.045289   0.048230   0.016285   0.020368   0.030817   0.027303   0.079675   0.025078   0.087566   0.134443   0.125151   0.118296   0.885714   0.854173   0.891791   0.641200   0.756639   0.577619   0.623251   0.604393   0.455311   0.193292   0.151151   0.082657   0.071503   0.046934   0.010658   0.042022   0.059627   0.067043   0.064441   0.081488   0.104004   0.074935   0.044424   0.076648   0.888044   0.900685   1.006931   0.857145   0.863976   0.670771   0.837751   0.502549   0.544723   0.251452   0.197664   0.142125   0.086416   0.061732   0.027961   0.035661   0.032352   0.061590   0.049365   0.063780   0.041962   0.085499   0.110149   0.094387   0.730622   0.920069   1.053318   0.943497   0.940104   0.738661   0.518512   0.579443   0.499591   0.392297   0.260616   0.231560   0.103431   0.105286   0.042527   0.047159   0.060234   0.024592   0.031506   0.035149   0.039565   0.128276   0.077567   0.383577   0.838991   0.798971   1.082478   0.852617   0.879296   0.769335   1.232461   0.871140   0.578608   0.450793   0.395279   0.252371   0.126975   0.211021   0.068163   0.065151   0.070971   0.087825   0.049155   0.059742   0.166266   0.104833   0.469258   0.138578   0.851402   0.953392   1.026304   0.916659   0.900624   0.796372   1.222628   1.014907   0.427135   0.434598   0.454353   0.455663   0.287029   0.238796   0.166782   0.134705   0.114985   0.033191   0.048919   0.055528   0.062724   0.534930   1.006143   0.975402   0.850802   0.874361   0.740791   0.890131   0.956836   0.762934   1.195596   0.730256   0.752417   0.434803   0.438237   0.441198   0.417042   0.466866   0.165245   0.176750   0.160492   0.715058   0.881108   1.098607   0.075345   0.480755   0.484341   0.379311   0.803542   0.691512   0.645106   0.783407   0.668539   0.767987   0.751504   0.844528   0.654044   0.433461   0.435584   0.456694   0.448592   0.508547   0.250633   0.547056   0.623488   0.445488   0.422711   0.467533   0.543158   0.441740   0.044577   0.655722   0.787132   0.903780   0.686920   0.773687   0.749117   0.826977   0.874109   0.724121   1.179458   0.400274   0.440250   0.466110   0.396506   0.467118   0.419631   0.515529   0.742862   0.373197   0.479112   0.487124   0.731684   0.491158   0.442223   0.691473   0.329303   0.319380   0.614964   0.653782   0.784323   0.859369   0.683164   0.789494   0.670186   0.423038   0.402022   0.390834   0.419126   0.421434   0.375431   0.443845   0.649334   0.606986   0.750010   0.373101   0.321906   0.511521   0.434442   0.671666   0.359860   0.599121   0.709068   0.726917   0.731048   0.846340   0.749490   0.134697   0.320421   0.425554   0.423880   0.469964   0.460620   0.428132   0.428334   0.584456   0.421496   0.593105   0.718080   0.472875   0.829516   0.746086   0.425332   0.363655   0.373315   0.566853   0.659128   0.686094   0.006174   0.548800   0.729852   0.189417   0.158121   0.418112   0.426297   0.407577   0.474993   0.686317   0.490875   0.540034   0.519910   0.410182   0.575222   0.526162   0.572518   0.654645   0.394182   0.318774   0.551183   0.365990   0.362937   0.360232   0.439805   0.638208   0.302060   0.178639   0.130041   0.410356   0.415565   0.440285   0.427704   0.571847   0.586712   0.477349   0.570469   0.469403   0.438007   0.418415   0.517454   0.699503   0.617932   0.747685   0.670989   0.325194   0.379107   0.441774   0.330360   0.708660   0.564161   0.067262   0.162732   0.464587   0.410653   0.420922   0.393562   0.409972   0.368425   0.443414   0.582571   0.463510   0.518732   0.426253   0.977334   0.465921   0.526523   0.383426    1.06973   0.284205   0.220607   0.098664   0.481631   0.397242   0.460759   0.433782   0.268275   0.478808   0.460782   0.511918   0.456057   0.470122   0.529023   0.462009   0.643478   0.408288   0.529258   0.613753   0.544766   0.656285   0.450668   0.652613   0.997555   0.574912   0.438510   0.541394   0.332095   0.246567   0.329231   0.410812   0.464439   0.473424   0.473634   0.469881   0.430400   0.396402   0.463390   0.430570   0.58562   0.396390   0.497103   0.505942   0.475498   0.695240   0.580768   0.575228   1.014441   0.590466   0.410363   0.574395   0.292372   0.577625   0.353905   0.354302   0.416433   0.467618   0.495323   0.471916   0.528285   0.544094   0.474325   0.595878   0.458716   0.647095   0.795823   0.401413    0.61910   0.388572   0.330793   0.747042   0.903758   0.250043   0.192773   0.219806   0.439959   0.462523   0.389415   0.411708   0.387106   0.509098   0.468053   0.479331   0.524084   0.526248   0.533797   0.545462   0.543883   0.521087   0.464813   0.522331   0.667525   0.610320   0.483820   0.321130   0.353249   0.223415   0.177163   0.335797   0.497413   0.454779   0.410168   0.424496   0.444077\n",
      "Validation MSE  42.563840  42.655938  42.276367  38.944628  40.688731  43.037043  42.840895  42.908589  43.318084  43.062481  43.017547  44.065465  46.615032  48.924133  49.098473  50.891379  50.505384  50.283993  50.231486  49.722535  50.084646  50.106735  51.763853  52.669425  42.411773  42.357661  42.180773  42.660528  40.257182  43.223311  43.147798  42.862730  43.106739  43.290308  43.119830  42.967448  43.144109  46.146670  48.952681  54.148424  52.314113  50.023989  50.182354  49.575005  50.104817  50.137344  52.582948  53.209329  43.632625  42.209025  42.146783  41.960317  42.557587  41.706279  40.700949  42.531134  42.874637  43.370687  43.180774  43.265899  42.817859  49.055832  46.996816  52.037279  52.473652  53.423369  54.655347  49.475125  50.869944  52.492091  50.769408  51.863038  42.810531  42.192735  42.642581  41.861811  42.70266  42.388014  42.799846  44.268825  41.950266  42.928490  43.154052  43.344146  43.416512  43.337643  54.361186  52.064972  51.841853  52.016978  53.813055  52.597679  50.958948  54.64217  50.822076  51.984448  42.674391  41.945052  39.885012  42.248134  40.780877  43.113655  42.760010  43.863633  42.909296  41.947942  42.447215  42.739966  43.341560  43.307853  47.892363  52.215327  51.394767  50.695582  51.344755  50.163524  48.858847  48.944312  49.20705  50.307889  43.253556  42.736323  43.446751  41.709463  43.113846  42.029839  42.594788  42.802084  42.757589  42.962668  43.338391  43.586567  44.093695  43.595376  48.996826  52.728409  52.533911  52.035281  50.996187  52.641942  48.753818  49.814705  48.981918  49.016873  45.030867  43.486357  43.045228  42.681213  42.770134  41.575255  41.770248  42.195709  42.061833  43.593557  41.972696  43.773968  44.715152  44.542820  44.411775  52.727899  52.482620  52.774714  50.708975  51.697885  50.130457  50.548350  50.377367  48.930606  45.696579  45.011422  43.662704  43.397467  42.731276  41.261501  42.579092  43.092136  43.285895  43.219129  43.635732  44.126397  43.481062  42.654545  43.522100  52.745868  52.842988  53.637071  52.505895  52.559270  50.969319  52.353354  49.409382  49.819990  46.535919  45.763440  44.853414  43.748162  43.148248  42.087513  42.368598  42.251815  43.144498  42.803734  43.201976  42.577185  43.727479  44.251255  43.923740  51.481179  52.990780  53.972337  53.167602  53.142114  51.548498  49.566551  50.147443  49.380019  48.255396  46.659546  46.260145  44.114588  44.152723  42.595137  42.738057  43.108422  41.952724  42.221062  42.350889  42.499767  44.601439  43.543926  48.158182  52.363153  52.043616  54.179845  52.470419  52.678299  51.802446  55.211392  52.615048  50.139670  48.883665  48.288414  46.548411  44.577125  45.963574  43.314226  43.237480  43.384336  43.779758  42.797560  43.095236  45.266402  44.143451  49.074200  44.790015  52.460880  53.241715  53.777885  52.964873  52.842524  52.022618  55.145466  53.695185  48.634298  48.713624  48.920670  48.934252  47.005082  46.361681  45.274916  44.719929  44.347182  42.281952  42.790578  42.980072  43.174391  49.725957  53.631319  53.405379  52.456172  52.640058  51.566276  52.761942  53.267435  51.749824  54.963053  51.478102  51.662946  48.715791  48.752076  48.783257  48.526023  49.049717  45.249543  45.436909  45.170347  51.349908  52.692318  54.293591  43.490925  49.191136  49.227351  48.110271  52.080459  51.148902  50.743672  51.917455  50.949853  51.791380  51.655379  52.406827  50.822699  48.701579  48.724054  48.944935  48.860718  49.468702  46.524766  49.842279  50.550485  48.828272  48.586979  49.056550  49.805013  48.788962  42.659281  50.837483  51.947753  52.866677  51.109348  51.838111  51.635573  52.267936  52.638101  51.426502  54.853322  48.343462  48.773285  49.041958  48.301967  49.052299  48.553905  49.537354  51.583542  48.041158  49.174497  49.255372  51.490086  49.295858  48.794034  51.148568  47.528933  47.408892  50.473497  50.820389  51.924913  52.523293  51.076916  51.966928  50.964222  48.590488  48.362657  48.239157  48.548475  48.573281  48.066464  48.811057  50.781112  50.401012  51.642986  48.040070  47.439603  49.497993  48.711969  50.977123  47.888578  50.329139  51.299057  51.450041  51.484753  52.421095  51.638667  44.719782  47.421561  48.617420  48.599509  49.081416  48.985496  48.644939  48.647088  50.193985  48.573944  50.273871  51.375496  49.111127  52.288112  51.610383  48.615040  47.932256  48.042492  50.029744  50.867440  51.102227  40.945251  49.858913  51.474710  45.636705  45.130434  48.537560  48.625360  48.423385  49.132694  51.104152  49.293021  49.775061  49.580217  48.451747  50.108105  49.641101  50.082842  50.827990  48.276279  47.401504  49.881607  47.959025  47.924004  47.892868  48.768601  50.682348  47.195167  45.467119  44.634235  48.453636  48.510069  48.773657  48.640368  50.076570  50.214871  49.156623  50.063660  49.075684  48.749648  48.540816  49.556202  51.217458  50.500365  51.623679  50.971225  47.479431  48.107968  48.789318  47.541625  51.295586  50.004422  43.291446  45.207802  49.026330  48.456865  48.567782  48.269416  48.449455  47.986854  48.806541  50.176505  49.015259  49.568705  48.624885  53.419667  49.040025  49.644609  48.156497   54.08943  46.968856  46.103594  44.015021  49.199995  48.310080  48.986933  48.704979  46.761351  49.171419  48.987168  49.501903  48.938333  49.083030  49.668863  48.999809  50.729218  48.431140  49.671139  50.462521  49.820398  50.842434  48.882362  50.810081  53.568505  50.105217  48.754954  49.788106  47.562410  46.469159  47.528078  48.458585  49.024804  49.116723  49.118857  49.080577  48.669076  48.300812  49.014029  48.670894  50.20477  48.300682  49.355257  49.442982  49.137822  51.180929  50.159757  50.108167  53.691797  50.249557  48.453711  50.100389  47.073164  50.130519  47.819618  47.824234  48.519449  49.057418  49.337504  49.101353  49.661703  49.813971  49.125897  50.299377  48.965847  50.761293  52.018182  48.355968   50.51092  48.213987  47.546825  51.618333  52.866511  46.516731  45.688580  46.091996  48.770225  49.005103  48.223377  48.468310  48.197644  49.474137  49.061875  49.176720  49.620900  49.641942  49.715029  49.827057  49.811957  49.591700  49.028645  49.603834  50.940996  50.431354  49.222093  47.430187  47.811993  46.144057  45.443526  47.606600  49.358338  48.925085  48.451587  48.606106  48.813494\n"
     ]
    }
   ],
   "source": [
    "# Initialize Results DataFrames\n",
    "results_test = pd.DataFrame(index=[\"Test MSE\", \"Test MAE\"], columns=[(p, q) for p in range(1, 6) for q in range(1, 6)])\n",
    "results_validate = pd.DataFrame(index=[\"Validation MSE\", \"Validation MAE\"], columns=[(p, q) for p in range(1, 6) for q in range(1, 6)])\n",
    "\n",
    "# ARMA Model Fitting and Error Calculation\n",
    "def fit_arma_model(p, q, train_data, test_data, val_data):\n",
    "    try:\n",
    "        # Fit ARMA model\n",
    "        model = sm.tsa.ARIMA(train_data[\"PM10_Combined_Trend_Residual\"], order=(p, 0, q))\n",
    "        res = model.fit()\n",
    "\n",
    "        # Forecast for test set\n",
    "        test_forecast = res.forecast(steps=len(test_data))\n",
    "        test_mse = ((test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values) ** 2).mean()\n",
    "        test_mae = np.abs(test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values).mean()\n",
    "\n",
    "        # Forecast for validation set\n",
    "        val_forecast = res.forecast(steps=len(val_data))\n",
    "        val_mse = ((val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values) ** 2).mean()\n",
    "        val_mae = np.abs(val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values).mean()\n",
    "\n",
    "        return test_mse, test_mae, val_mse, val_mae\n",
    "    except Exception as e:\n",
    "        print(f\"Error for (p, q)=({p}, {q}): {e}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
<<<<<<< HEAD
    "# Print the results in a more readable format\n",
    "print(final_results.to_string(index=True))  # Display the results in a tabular format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing q values: 100%|██████████| 24/24 [00:00<00:00, 23791.84it/s]\n",
      "Processing q values: 100%|██████████| 24/24 [00:26<00:00,  1.10s/it]\n",
      "Processing q values: 100%|██████████| 24/24 [00:36<00:00,  1.51s/it]\n",
      "Processing q values: 100%|██████████| 24/24 [01:26<00:00,  3.60s/it]\n",
      "Processing q values: 100%|██████████| 24/24 [01:04<00:00,  2.68s/it]\n",
      "Processing q values: 100%|██████████| 24/24 [01:54<00:00,  4.77s/it]\n",
      "Processing q values: 100%|██████████| 24/24 [00:57<00:00,  2.39s/it]\n",
      "Processing q values: 100%|██████████| 24/24 [02:06<00:00,  5.29s/it]\n",
      "Processing q values: 100%|██████████| 24/24 [01:04<00:00,  2.67s/it]\n",
      "Processing q values: 100%|██████████| 24/24 [02:10<00:00,  5.42s/it]\n",
      "Processing q values: 100%|██████████| 24/24 [01:15<00:00,  3.15s/it]\n",
      "Processing q values: 100%|██████████| 24/24 [02:34<00:00,  6.43s/it]\n",
      "Processing q values: 100%|██████████| 24/24 [01:20<00:00,  3.34s/it]]\n",
      "Processing q values: 100%|██████████| 24/24 [02:49<00:00,  7.07s/it]]\n",
      "Processing q values: 100%|██████████| 24/24 [01:10<00:00,  2.95s/it]]\n",
      "Processing q values: 100%|██████████| 24/24 [03:18<00:00,  8.28s/it]]\n",
      "Processing q values: 100%|██████████| 24/24 [01:24<00:00,  3.52s/it]]\n",
      "Processing q values: 100%|██████████| 24/24 [04:08<00:00, 10.34s/it]]\n",
      "Processing q values: 100%|██████████| 24/24 [01:42<00:00,  4.29s/it]]\n",
      "Processing q values: 100%|██████████| 24/24 [04:37<00:00, 11.56s/it]]\n",
      "Processing q values: 100%|██████████| 24/24 [02:12<00:00,  5.54s/it]]\n",
      "Processing q values: 100%|██████████| 24/24 [05:11<00:00, 12.96s/it]]\n",
      "Processing q values: 100%|██████████| 24/24 [02:16<00:00,  5.68s/it]]\n",
      "Processing q values: 100%|██████████| 24/24 [05:45<00:00, 14.41s/it]]\n",
      "Processing p values: 100%|██████████| 24/24 [51:34<00:00, 128.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  p=1_q=1    p=1_q=2    p=1_q=3    p=1_q=4    p=1_q=5    p=1_q=6    p=1_q=7    p=1_q=8    p=1_q=9   p=1_q=10   p=1_q=11   p=1_q=12   p=1_q=13   p=1_q=14   p=1_q=15   p=1_q=16   p=1_q=17   p=1_q=18   p=1_q=19   p=1_q=20   p=1_q=21   p=1_q=22   p=1_q=23   p=1_q=24    p=2_q=1    p=2_q=2    p=2_q=3    p=2_q=4    p=2_q=5    p=2_q=6    p=2_q=7    p=2_q=8    p=2_q=9   p=2_q=10   p=2_q=11   p=2_q=12   p=2_q=13   p=2_q=14   p=2_q=15   p=2_q=16   p=2_q=17   p=2_q=18   p=2_q=19   p=2_q=20   p=2_q=21   p=2_q=22   p=2_q=23   p=2_q=24    p=3_q=1    p=3_q=2    p=3_q=3    p=3_q=4    p=3_q=5    p=3_q=6    p=3_q=7    p=3_q=8    p=3_q=9   p=3_q=10   p=3_q=11   p=3_q=12   p=3_q=13   p=3_q=14   p=3_q=15   p=3_q=16   p=3_q=17   p=3_q=18   p=3_q=19   p=3_q=20   p=3_q=21   p=3_q=22   p=3_q=23   p=3_q=24    p=4_q=1    p=4_q=2    p=4_q=3    p=4_q=4   p=4_q=5    p=4_q=6    p=4_q=7    p=4_q=8    p=4_q=9   p=4_q=10   p=4_q=11   p=4_q=12   p=4_q=13   p=4_q=14   p=4_q=15   p=4_q=16   p=4_q=17   p=4_q=18   p=4_q=19   p=4_q=20   p=4_q=21  p=4_q=22   p=4_q=23   p=4_q=24    p=5_q=1    p=5_q=2    p=5_q=3    p=5_q=4    p=5_q=5    p=5_q=6    p=5_q=7    p=5_q=8    p=5_q=9   p=5_q=10   p=5_q=11   p=5_q=12   p=5_q=13   p=5_q=14   p=5_q=15   p=5_q=16   p=5_q=17   p=5_q=18   p=5_q=19   p=5_q=20   p=5_q=21   p=5_q=22  p=5_q=23   p=5_q=24    p=6_q=1    p=6_q=2    p=6_q=3    p=6_q=4    p=6_q=5    p=6_q=6    p=6_q=7    p=6_q=8    p=6_q=9   p=6_q=10   p=6_q=11   p=6_q=12   p=6_q=13   p=6_q=14   p=6_q=15   p=6_q=16   p=6_q=17   p=6_q=18   p=6_q=19   p=6_q=20   p=6_q=21   p=6_q=22   p=6_q=23   p=6_q=24    p=7_q=1    p=7_q=2    p=7_q=3    p=7_q=4    p=7_q=5    p=7_q=6    p=7_q=7    p=7_q=8    p=7_q=9   p=7_q=10   p=7_q=11   p=7_q=12   p=7_q=13   p=7_q=14   p=7_q=15   p=7_q=16   p=7_q=17   p=7_q=18   p=7_q=19   p=7_q=20   p=7_q=21   p=7_q=22   p=7_q=23   p=7_q=24    p=8_q=1    p=8_q=2    p=8_q=3    p=8_q=4    p=8_q=5    p=8_q=6    p=8_q=7    p=8_q=8    p=8_q=9   p=8_q=10   p=8_q=11   p=8_q=12   p=8_q=13   p=8_q=14   p=8_q=15   p=8_q=16   p=8_q=17   p=8_q=18   p=8_q=19   p=8_q=20   p=8_q=21   p=8_q=22   p=8_q=23   p=8_q=24    p=9_q=1    p=9_q=2    p=9_q=3    p=9_q=4    p=9_q=5    p=9_q=6    p=9_q=7    p=9_q=8    p=9_q=9   p=9_q=10   p=9_q=11   p=9_q=12   p=9_q=13   p=9_q=14   p=9_q=15   p=9_q=16   p=9_q=17   p=9_q=18   p=9_q=19   p=9_q=20   p=9_q=21   p=9_q=22   p=9_q=23   p=9_q=24   p=10_q=1   p=10_q=2   p=10_q=3   p=10_q=4   p=10_q=5   p=10_q=6   p=10_q=7   p=10_q=8   p=10_q=9  p=10_q=10  p=10_q=11  p=10_q=12  p=10_q=13  p=10_q=14  p=10_q=15  p=10_q=16  p=10_q=17  p=10_q=18  p=10_q=19  p=10_q=20  p=10_q=21  p=10_q=22  p=10_q=23  p=10_q=24   p=11_q=1   p=11_q=2   p=11_q=3   p=11_q=4   p=11_q=5   p=11_q=6   p=11_q=7   p=11_q=8   p=11_q=9  p=11_q=10  p=11_q=11  p=11_q=12  p=11_q=13  p=11_q=14  p=11_q=15  p=11_q=16  p=11_q=17  p=11_q=18  p=11_q=19  p=11_q=20  p=11_q=21  p=11_q=22  p=11_q=23  p=11_q=24   p=12_q=1   p=12_q=2   p=12_q=3   p=12_q=4   p=12_q=5   p=12_q=6   p=12_q=7   p=12_q=8   p=12_q=9  p=12_q=10  p=12_q=11  p=12_q=12  p=12_q=13  p=12_q=14  p=12_q=15  p=12_q=16  p=12_q=17  p=12_q=18  p=12_q=19  p=12_q=20  p=12_q=21  p=12_q=22  p=12_q=23  p=12_q=24   p=13_q=1   p=13_q=2   p=13_q=3   p=13_q=4   p=13_q=5   p=13_q=6   p=13_q=7   p=13_q=8   p=13_q=9  p=13_q=10  p=13_q=11  p=13_q=12  p=13_q=13  p=13_q=14  p=13_q=15  p=13_q=16  p=13_q=17  p=13_q=18  p=13_q=19  p=13_q=20  p=13_q=21  p=13_q=22  p=13_q=23  p=13_q=24   p=14_q=1   p=14_q=2   p=14_q=3   p=14_q=4   p=14_q=5   p=14_q=6   p=14_q=7   p=14_q=8   p=14_q=9  p=14_q=10  p=14_q=11  p=14_q=12  p=14_q=13  p=14_q=14  p=14_q=15  p=14_q=16  p=14_q=17  p=14_q=18  p=14_q=19  p=14_q=20  p=14_q=21  p=14_q=22  p=14_q=23  p=14_q=24   p=15_q=1   p=15_q=2   p=15_q=3   p=15_q=4   p=15_q=5   p=15_q=6   p=15_q=7   p=15_q=8   p=15_q=9  p=15_q=10  p=15_q=11  p=15_q=12  p=15_q=13  p=15_q=14  p=15_q=15  p=15_q=16  p=15_q=17  p=15_q=18  p=15_q=19  p=15_q=20  p=15_q=21  p=15_q=22  p=15_q=23  p=15_q=24   p=16_q=1   p=16_q=2   p=16_q=3   p=16_q=4   p=16_q=5   p=16_q=6   p=16_q=7   p=16_q=8   p=16_q=9  p=16_q=10  p=16_q=11  p=16_q=12  p=16_q=13  p=16_q=14  p=16_q=15  p=16_q=16  p=16_q=17  p=16_q=18  p=16_q=19  p=16_q=20  p=16_q=21  p=16_q=22  p=16_q=23  p=16_q=24   p=17_q=1   p=17_q=2   p=17_q=3   p=17_q=4   p=17_q=5   p=17_q=6   p=17_q=7   p=17_q=8   p=17_q=9  p=17_q=10  p=17_q=11  p=17_q=12  p=17_q=13  p=17_q=14  p=17_q=15  p=17_q=16  p=17_q=17  p=17_q=18  p=17_q=19  p=17_q=20  p=17_q=21  p=17_q=22  p=17_q=23  p=17_q=24   p=18_q=1   p=18_q=2   p=18_q=3   p=18_q=4   p=18_q=5   p=18_q=6   p=18_q=7   p=18_q=8   p=18_q=9  p=18_q=10  p=18_q=11  p=18_q=12  p=18_q=13  p=18_q=14  p=18_q=15  p=18_q=16  p=18_q=17  p=18_q=18  p=18_q=19  p=18_q=20  p=18_q=21  p=18_q=22  p=18_q=23  p=18_q=24   p=19_q=1   p=19_q=2   p=19_q=3   p=19_q=4   p=19_q=5   p=19_q=6   p=19_q=7   p=19_q=8   p=19_q=9  p=19_q=10  p=19_q=11  p=19_q=12  p=19_q=13  p=19_q=14  p=19_q=15  p=19_q=16  p=19_q=17  p=19_q=18  p=19_q=19  p=19_q=20  p=19_q=21  p=19_q=22  p=19_q=23  p=19_q=24   p=20_q=1   p=20_q=2   p=20_q=3   p=20_q=4   p=20_q=5   p=20_q=6   p=20_q=7   p=20_q=8   p=20_q=9  p=20_q=10  p=20_q=11  p=20_q=12  p=20_q=13  p=20_q=14  p=20_q=15  p=20_q=16  p=20_q=17  p=20_q=18  p=20_q=19  p=20_q=20  p=20_q=21  p=20_q=22  p=20_q=23  p=20_q=24   p=21_q=1   p=21_q=2   p=21_q=3   p=21_q=4   p=21_q=5   p=21_q=6   p=21_q=7   p=21_q=8   p=21_q=9  p=21_q=10  p=21_q=11  p=21_q=12  p=21_q=13  p=21_q=14  p=21_q=15  p=21_q=16  p=21_q=17  p=21_q=18  p=21_q=19  p=21_q=20  p=21_q=21  p=21_q=22  p=21_q=23  p=21_q=24   p=22_q=1   p=22_q=2   p=22_q=3   p=22_q=4   p=22_q=5   p=22_q=6   p=22_q=7  p=22_q=8   p=22_q=9  p=22_q=10  p=22_q=11  p=22_q=12  p=22_q=13  p=22_q=14  p=22_q=15  p=22_q=16  p=22_q=17  p=22_q=18  p=22_q=19  p=22_q=20  p=22_q=21  p=22_q=22  p=22_q=23  p=22_q=24   p=23_q=1   p=23_q=2   p=23_q=3   p=23_q=4   p=23_q=5   p=23_q=6   p=23_q=7   p=23_q=8   p=23_q=9  p=23_q=10  p=23_q=11  p=23_q=12  p=23_q=13  p=23_q=14  p=23_q=15  p=23_q=16  p=23_q=17  p=23_q=18  p=23_q=19  p=23_q=20  p=23_q=21  p=23_q=22  p=23_q=23  p=23_q=24   p=24_q=1   p=24_q=2   p=24_q=3   p=24_q=4   p=24_q=5   p=24_q=6   p=24_q=7   p=24_q=8   p=24_q=9  p=24_q=10  p=24_q=11  p=24_q=12  p=24_q=13  p=24_q=14  p=24_q=15  p=24_q=16  p=24_q=17  p=24_q=18  p=24_q=19  p=24_q=20  p=24_q=21  p=24_q=22  p=24_q=23  p=24_q=24\n",
      "Test MSE         0.041544   0.044469   0.033034   0.006354   0.003422   0.057594   0.050635   0.052988   0.068316   0.058529   0.056883   0.101066   0.257299   0.454687   0.471634   0.661856   0.618488   0.594204   0.588509   0.534575   0.572711   0.575075   0.764638   0.878149   0.036925   0.035345   0.030415   0.044618   0.000604   0.064602   0.061715   0.051388   0.060171   0.067217   0.060661   0.055076   0.061575   0.223597   0.457443   1.078040   0.832794   0.566241   0.583202   0.519377   0.574870   0.578358   0.867014   0.949062   0.081354   0.031178   0.029509   0.024776   0.041349   0.018979   0.003535   0.040528   0.051801   0.070420   0.062968   0.066259   0.049846   0.467463   0.286384   0.798186   0.853029   0.977834   1.150581   0.509199   0.659413   0.855382   0.648011   0.776735   0.049596   0.030737   0.044039   0.022439   0.04599   0.036227   0.049233   0.111028   0.024532   0.053689   0.061951   0.069355   0.072278   0.069095   1.108240   0.801619   0.774144   0.795674   1.031167   0.868907   0.669581   1.14867   0.653973   0.791655   0.045067   0.024407   0.000023   0.032250   0.004319   0.060430   0.047891   0.091620   0.053013   0.024476   0.037978   0.047222   0.069251   0.067910   0.360188   0.820371   0.720360   0.639694   0.714450   0.581173   0.448413   0.456634   0.48233   0.596805   0.065777   0.047101   0.073517   0.019047   0.060437   0.026494   0.042516   0.049309   0.047810   0.054905   0.069125   0.079376   0.102422   0.079753   0.461719   0.885780   0.860727   0.797939   0.673856   0.874604   0.438402   0.544171   0.460273   0.463667   0.152280   0.075155   0.057894   0.045289   0.048230   0.016285   0.020368   0.030817   0.027303   0.079675   0.025078   0.087566   0.134443   0.125151   0.118296   0.885714   0.854173   0.891791   0.641200   0.756639   0.577619   0.623251   0.604393   0.455311   0.193292   0.151151   0.082657   0.071503   0.046934   0.010658   0.042022   0.059627   0.067043   0.064441   0.081488   0.104004   0.074935   0.044424   0.076648   0.888044   0.900685   1.006931   0.857145   0.863976   0.670771   0.837751   0.502549   0.544723   0.251452   0.197664   0.142125   0.086416   0.061732   0.027961   0.035661   0.032352   0.061590   0.049365   0.063780   0.041962   0.085499   0.110149   0.094387   0.730622   0.920069   1.053318   0.943497   0.940104   0.738661   0.518512   0.579443   0.499591   0.392297   0.260616   0.231560   0.103431   0.105286   0.042527   0.047159   0.060234   0.024592   0.031506   0.035149   0.039565   0.128276   0.077567   0.383577   0.838991   0.798971   1.082478   0.852617   0.879296   0.769335   1.232461   0.871140   0.578608   0.450793   0.395279   0.252371   0.126975   0.211021   0.068163   0.065151   0.070971   0.087825   0.049155   0.059742   0.166266   0.104833   0.469258   0.138578   0.851402   0.953392   1.026304   0.916659   0.900624   0.796372   1.222628   1.014907   0.427135   0.434598   0.454353   0.455663   0.287029   0.238796   0.166782   0.134705   0.114985   0.033191   0.048919   0.055528   0.062724   0.534930   1.006143   0.975402   0.850802   0.874361   0.740791   0.890131   0.956836   0.762934   1.195596   0.730256   0.752417   0.434803   0.438237   0.441198   0.417042   0.466866   0.165245   0.176750   0.160492   0.715058   0.881108   1.098607   0.075345   0.480755   0.484341   0.379311   0.803542   0.691512   0.645106   0.783407   0.668539   0.767987   0.751504   0.844528   0.654044   0.433461   0.435584   0.456694   0.448592   0.508547   0.250633   0.547056   0.623488   0.445488   0.422711   0.467533   0.543158   0.441740   0.044577   0.655722   0.787132   0.903780   0.686920   0.773687   0.749117   0.826977   0.874109   0.724121   1.179458   0.400274   0.440250   0.466110   0.396506   0.467118   0.419631   0.515529   0.742862   0.373197   0.479112   0.487124   0.731684   0.491158   0.442223   0.691473   0.329303   0.319380   0.614964   0.653782   0.784323   0.859369   0.683164   0.789494   0.670186   0.423038   0.402022   0.390834   0.419126   0.421434   0.375431   0.443845   0.649334   0.606986   0.750010   0.373101   0.321906   0.511521   0.434442   0.671666   0.359860   0.599121   0.709068   0.726917   0.731048   0.846340   0.749490   0.134697   0.320421   0.425554   0.423880   0.469964   0.460620   0.428132   0.428334   0.584456   0.421496   0.593105   0.718080   0.472875   0.829516   0.746086   0.425332   0.363655   0.373315   0.566853   0.659128   0.686094   0.006174   0.548800   0.729852   0.189417   0.158121   0.418112   0.426297   0.407577   0.474993   0.686317   0.490875   0.540034   0.519910   0.410182   0.575222   0.526162   0.572518   0.654645   0.394182   0.318774   0.551183   0.365990   0.362937   0.360232   0.439805   0.638208   0.302060   0.178639   0.130041   0.410356   0.415565   0.440285   0.427704   0.571847   0.586712   0.477349   0.570469   0.469403   0.438007   0.418415   0.517454   0.699503   0.617932   0.747685   0.670989   0.325194   0.379107   0.441774   0.330360   0.708660   0.564161   0.067262   0.162732   0.464587   0.410653   0.420922   0.393562   0.409972   0.368425   0.443414   0.582571   0.463510   0.518732   0.426253   0.977334   0.465921   0.526523   0.383426    1.06973   0.284205   0.220607   0.098664   0.481631   0.397242   0.460759   0.433782   0.268275   0.478808   0.460782   0.511918   0.456057   0.470122   0.529023   0.462009   0.643478   0.408288   0.529258   0.613753   0.544766   0.656285   0.450668   0.652613   0.997555   0.574912   0.438510   0.541394   0.332095   0.246567   0.329231   0.410812   0.464439   0.473424   0.473634   0.469881   0.430400   0.396402   0.463390   0.430570   0.58562   0.396390   0.497103   0.505942   0.475498   0.695240   0.580768   0.575228   1.014441   0.590466   0.410363   0.574395   0.292372   0.577625   0.353905   0.354302   0.416433   0.467618   0.495323   0.471916   0.528285   0.544094   0.474325   0.595878   0.458716   0.647095   0.795823   0.401413    0.61910   0.388572   0.330793   0.747042   0.903758   0.250043   0.192773   0.219806   0.439959   0.462523   0.389415   0.411708   0.387106   0.509098   0.468053   0.479331   0.524084   0.526248   0.533797   0.545462   0.543883   0.521087   0.464813   0.522331   0.667525   0.610320   0.483820   0.321130   0.353249   0.223415   0.177163   0.335797   0.497413   0.454779   0.410168   0.424496   0.444077\n",
      "Validation MSE  42.563840  42.655938  42.276367  38.944628  40.688731  43.037043  42.840895  42.908589  43.318084  43.062481  43.017547  44.065465  46.615032  48.924133  49.098473  50.891379  50.505384  50.283993  50.231486  49.722535  50.084646  50.106735  51.763853  52.669425  42.411773  42.357661  42.180773  42.660528  40.257182  43.223311  43.147798  42.862730  43.106739  43.290308  43.119830  42.967448  43.144109  46.146670  48.952681  54.148424  52.314113  50.023989  50.182354  49.575005  50.104817  50.137344  52.582948  53.209329  43.632625  42.209025  42.146783  41.960317  42.557587  41.706279  40.700949  42.531134  42.874637  43.370687  43.180774  43.265899  42.817859  49.055832  46.996816  52.037279  52.473652  53.423369  54.655347  49.475125  50.869944  52.492091  50.769408  51.863038  42.810531  42.192735  42.642581  41.861811  42.70266  42.388014  42.799846  44.268825  41.950266  42.928490  43.154052  43.344146  43.416512  43.337643  54.361186  52.064972  51.841853  52.016978  53.813055  52.597679  50.958948  54.64217  50.822076  51.984448  42.674391  41.945052  39.885012  42.248134  40.780877  43.113655  42.760010  43.863633  42.909296  41.947942  42.447215  42.739966  43.341560  43.307853  47.892363  52.215327  51.394767  50.695582  51.344755  50.163524  48.858847  48.944312  49.20705  50.307889  43.253556  42.736323  43.446751  41.709463  43.113846  42.029839  42.594788  42.802084  42.757589  42.962668  43.338391  43.586567  44.093695  43.595376  48.996826  52.728409  52.533911  52.035281  50.996187  52.641942  48.753818  49.814705  48.981918  49.016873  45.030867  43.486357  43.045228  42.681213  42.770134  41.575255  41.770248  42.195709  42.061833  43.593557  41.972696  43.773968  44.715152  44.542820  44.411775  52.727899  52.482620  52.774714  50.708975  51.697885  50.130457  50.548350  50.377367  48.930606  45.696579  45.011422  43.662704  43.397467  42.731276  41.261501  42.579092  43.092136  43.285895  43.219129  43.635732  44.126397  43.481062  42.654545  43.522100  52.745868  52.842988  53.637071  52.505895  52.559270  50.969319  52.353354  49.409382  49.819990  46.535919  45.763440  44.853414  43.748162  43.148248  42.087513  42.368598  42.251815  43.144498  42.803734  43.201976  42.577185  43.727479  44.251255  43.923740  51.481179  52.990780  53.972337  53.167602  53.142114  51.548498  49.566551  50.147443  49.380019  48.255396  46.659546  46.260145  44.114588  44.152723  42.595137  42.738057  43.108422  41.952724  42.221062  42.350889  42.499767  44.601439  43.543926  48.158182  52.363153  52.043616  54.179845  52.470419  52.678299  51.802446  55.211392  52.615048  50.139670  48.883665  48.288414  46.548411  44.577125  45.963574  43.314226  43.237480  43.384336  43.779758  42.797560  43.095236  45.266402  44.143451  49.074200  44.790015  52.460880  53.241715  53.777885  52.964873  52.842524  52.022618  55.145466  53.695185  48.634298  48.713624  48.920670  48.934252  47.005082  46.361681  45.274916  44.719929  44.347182  42.281952  42.790578  42.980072  43.174391  49.725957  53.631319  53.405379  52.456172  52.640058  51.566276  52.761942  53.267435  51.749824  54.963053  51.478102  51.662946  48.715791  48.752076  48.783257  48.526023  49.049717  45.249543  45.436909  45.170347  51.349908  52.692318  54.293591  43.490925  49.191136  49.227351  48.110271  52.080459  51.148902  50.743672  51.917455  50.949853  51.791380  51.655379  52.406827  50.822699  48.701579  48.724054  48.944935  48.860718  49.468702  46.524766  49.842279  50.550485  48.828272  48.586979  49.056550  49.805013  48.788962  42.659281  50.837483  51.947753  52.866677  51.109348  51.838111  51.635573  52.267936  52.638101  51.426502  54.853322  48.343462  48.773285  49.041958  48.301967  49.052299  48.553905  49.537354  51.583542  48.041158  49.174497  49.255372  51.490086  49.295858  48.794034  51.148568  47.528933  47.408892  50.473497  50.820389  51.924913  52.523293  51.076916  51.966928  50.964222  48.590488  48.362657  48.239157  48.548475  48.573281  48.066464  48.811057  50.781112  50.401012  51.642986  48.040070  47.439603  49.497993  48.711969  50.977123  47.888578  50.329139  51.299057  51.450041  51.484753  52.421095  51.638667  44.719782  47.421561  48.617420  48.599509  49.081416  48.985496  48.644939  48.647088  50.193985  48.573944  50.273871  51.375496  49.111127  52.288112  51.610383  48.615040  47.932256  48.042492  50.029744  50.867440  51.102227  40.945251  49.858913  51.474710  45.636705  45.130434  48.537560  48.625360  48.423385  49.132694  51.104152  49.293021  49.775061  49.580217  48.451747  50.108105  49.641101  50.082842  50.827990  48.276279  47.401504  49.881607  47.959025  47.924004  47.892868  48.768601  50.682348  47.195167  45.467119  44.634235  48.453636  48.510069  48.773657  48.640368  50.076570  50.214871  49.156623  50.063660  49.075684  48.749648  48.540816  49.556202  51.217458  50.500365  51.623679  50.971225  47.479431  48.107968  48.789318  47.541625  51.295586  50.004422  43.291446  45.207802  49.026330  48.456865  48.567782  48.269416  48.449455  47.986854  48.806541  50.176505  49.015259  49.568705  48.624885  53.419667  49.040025  49.644609  48.156497   54.08943  46.968856  46.103594  44.015021  49.199995  48.310080  48.986933  48.704979  46.761351  49.171419  48.987168  49.501903  48.938333  49.083030  49.668863  48.999809  50.729218  48.431140  49.671139  50.462521  49.820398  50.842434  48.882362  50.810081  53.568505  50.105217  48.754954  49.788106  47.562410  46.469159  47.528078  48.458585  49.024804  49.116723  49.118857  49.080577  48.669076  48.300812  49.014029  48.670894  50.20477  48.300682  49.355257  49.442982  49.137822  51.180929  50.159757  50.108167  53.691797  50.249557  48.453711  50.100389  47.073164  50.130519  47.819618  47.824234  48.519449  49.057418  49.337504  49.101353  49.661703  49.813971  49.125897  50.299377  48.965847  50.761293  52.018182  48.355968   50.51092  48.213987  47.546825  51.618333  52.866511  46.516731  45.688580  46.091996  48.770225  49.005103  48.223377  48.468310  48.197644  49.474137  49.061875  49.176720  49.620900  49.641942  49.715029  49.827057  49.811957  49.591700  49.028645  49.603834  50.940996  50.431354  49.222093  47.430187  47.811993  46.144057  45.443526  47.606600  49.358338  48.925085  48.451587  48.606106  48.813494\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "# Assuming 'y' is your DataFrame\n",
    "# Ensure the 'PM10_Combined_Trend_Residual' column is numeric\n",
    "y['PM10_Combined_Trend_Residual'] = pd.to_numeric(y['PM10_Combined_Trend_Residual'], errors='coerce')\n",
    "\n",
    "# Optionally, handle missing values (e.g., by filling or dropping)\n",
    "y = y.dropna(subset=['PM10_Combined_Trend_Residual'])  # Drop rows with NaN values in the relevant column\n",
    "\n",
    "# Define the length of the dataset and split sizes\n",
    "n = len(y)  # Length of the DataFrame y\n",
    "train_size_initial = int(n * 0.7)  # 70% of the data for training\n",
    "test_size = int(n * 0.1)   # 10% of the data for testing\n",
    "validate_size = int(n * 0.1)  # 10% of the data for validation\n",
    "\n",
    "# Define results DataFrame to store MSE for test and validation sets separately\n",
    "results_test = pd.DataFrame(np.zeros((1, 576)))  # MSE for test set\n",
    "results_test.columns = [f\"p={p}_q={q}\" for p in range(1, 25) for q in range(1, 25)]  # Column names for ARMA orders\n",
    "\n",
    "results_validate = pd.DataFrame(np.zeros((1, 576)))  # MSE for validation set\n",
    "results_validate.columns = [f\"p={p}_q={q}\" for p in range(1, 25) for q in range(1, 25)]  # Column names for ARMA orders\n",
    "\n",
    "# Use the first 50% of the data for the initial training set (50% of the train_size)\n",
    "train_size_current = int(train_size_initial * 0.5)  # Initial 50% of the train set\n",
    "testing_start = train_size_current\n",
    "testing_end = testing_start + test_size\n",
    "\n",
    "# Expanding the training set by adding the next 10% in each iteration\n",
    "training = y[:train_size_current]  # Initial training set\n",
    "testing = y[testing_start:testing_end]  # Testing set\n",
    "validation_start = testing_end\n",
    "validation_end = validation_start + validate_size\n",
    "validation = y[validation_start:validation_end]  # Validation set\n",
    "\n",
    "# Function to fit ARMA model and compute MSE\n",
    "def fit_arma(p, q, training_data, testing, validation):\n",
    "    try:\n",
    "        # Fit ARMA model with (p, 0, q) order (AR=p, differencing=0, MA=q)\n",
    "        mod = sm.tsa.ARIMA(training_data['PM10_Combined_Trend_Residual'], order=(p, 0, q))\n",
    "        res = mod.fit()\n",
    "        \n",
    "        # One-step ahead forecast for the testing set\n",
    "        forecast_test = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "        \n",
    "        # One-step ahead forecast for the validation set\n",
    "        forecast_validate = res.forecast(steps=1, signal_only=False)  # Forecasting just 1 step ahead\n",
    "        \n",
    "        # Calculate Mean Squared Error for the test set\n",
    "        mse_test = ((testing['PM10_Combined_Trend_Residual'].values[:1] - forecast_test.values) ** 2).mean()\n",
    "        \n",
    "        # Calculate Mean Squared Error for the validation set\n",
    "        mse_validate = ((validation['PM10_Combined_Trend_Residual'].values[:1] - forecast_validate.values) ** 2).mean()\n",
    "        \n",
    "    except np.linalg.LinAlgError:\n",
    "        mse_test = np.nan\n",
    "        mse_validate = np.nan\n",
    "    \n",
    "    return mse_test, mse_validate\n",
    "\n",
    "# Use joblib's Parallel to run the fit_arma function in parallel for different p, q combinations\n",
    "# Use tqdm to show a progress bar for the iterations\n",
=======
    "# Run in parallel for ARMA combinations (p, q) from (1, 1) to (5, 5)\n",
>>>>>>> ee4e503d5849336f46c11a5724c2d7a40b17aa2b
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(fit_arma_model)(p, q, train_data, test_data, val_data) \n",
    "    for p in range(1, 6) for q in range(1, 6)\n",
    ")\n",
    "\n",
    "# Store results in DataFrames\n",
    "for idx, (test_mse, test_mae, val_mse, val_mae) in enumerate(results):\n",
    "    p, q = results_test.columns[idx]\n",
    "    results_test.loc[\"Test MSE\", (p, q)] = test_mse\n",
    "    results_test.loc[\"Test MAE\", (p, q)] = test_mae\n",
    "    results_validate.loc[\"Validation MSE\", (p, q)] = val_mse\n",
    "    results_validate.loc[\"Validation MAE\", (p, q)] = val_mae\n",
    "\n",
    "# Combine results into a single DataFrame for display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0)\n",
    "print(final_results.to_string(index=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
