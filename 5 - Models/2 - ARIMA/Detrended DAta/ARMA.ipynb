{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>PM10_Combined_Trend_Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>75.197962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>51.472071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>32.710483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>24.801767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>9.683660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Datum  PM10_Combined_Trend_Residual\n",
       "0  2022-01-01 00:00:00+00:00                     75.197962\n",
       "1  2022-01-01 01:00:00+00:00                     51.472071\n",
       "2  2022-01-01 02:00:00+00:00                     32.710483\n",
       "3  2022-01-01 03:00:00+00:00                     24.801767\n",
       "4  2022-01-01 04:00:00+00:00                      9.683660"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "y = pd.read_csv('../Detrended DAta/TargetCutto50MostImpFeatures_DF.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data\n",
    "def train_test_val_split(data, train_ratio=0.7, test_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Splits the dataset into Train, Test, and Validation sets.\n",
    "    Parameters:\n",
    "        data: DataFrame - The full dataset to split.\n",
    "        train_ratio: float - Proportion of data to use for training.\n",
    "        test_ratio: float - Proportion of data to use for testing.\n",
    "    Returns:\n",
    "        train_data, test_data, val_data - DataFrames for train, test, and validation splits.\n",
    "    \"\"\"\n",
    "    train_size = int(len(data) * train_ratio)\n",
    "    test_size = int(len(data) * test_ratio)\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:train_size + test_size]\n",
    "    val_data = data[train_size + test_size:]\n",
    "    return train_data, test_data, val_data\n",
    "\n",
    "# Call the function to split the data\n",
    "train_data, test_data, val_data = train_test_val_split(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Results DataFrames\n",
    "results_test = pd.DataFrame(index=[\"Test MSE\", \"Test MAE\"], columns=np.arange(1, 25))\n",
    "results_validate = pd.DataFrame(index=[\"Validation MSE\", \"Validation MAE\"], columns=np.arange(1, 25))\n",
    "\n",
    "# AR Model Fitting and Error Calculation\n",
    "def fit_ar_model(p, train_data, test_data, val_data):\n",
    "    try:\n",
    "        # Fit AR model\n",
    "        model = sm.tsa.ARIMA(train_data[\"PM10_Combined_Trend_Residual\"], order=(p, 0, 0))\n",
    "        res = model.fit()\n",
    "\n",
    "        # Forecast for test set\n",
    "        test_forecast = res.forecast(steps=len(test_data))\n",
    "        test_mse = ((test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values) ** 2).mean()\n",
    "        test_mae = np.abs(test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values).mean()\n",
    "\n",
    "        # Forecast for validation set\n",
    "        val_forecast = res.forecast(steps=len(val_data))\n",
    "        val_mse = ((val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values) ** 2).mean()\n",
    "        val_mae = np.abs(val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values).mean()\n",
    "\n",
    "        return test_mse, test_mae, val_mse, val_mae\n",
    "    except Exception as e:\n",
    "        print(f\"Error for p={p}: {e}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "# Run in parallel for AR lags (p) from 1 to 24\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_ar_model)(p, train_data, test_data, val_data) for p in range(1, 25))\n",
    "\n",
    "# Store results in DataFrames\n",
    "for idx, (test_mse, test_mae, val_mse, val_mae) in enumerate(results):\n",
    "    p_value = idx + 1\n",
    "    results_test.loc[\"Test MSE\", p_value] = test_mse\n",
    "    results_test.loc[\"Test MAE\", p_value] = test_mae\n",
    "    results_validate.loc[\"Validation MSE\", p_value] = val_mse\n",
    "    results_validate.loc[\"Validation MAE\", p_value] = val_mae\n",
    "\n",
    "# Combine results into a single DataFrame for display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0)\n",
    "print(final_results.to_string(index=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MA Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      q=1        q=2        q=3        q=4        q=5        q=6        q=7        q=8        q=9       q=10       q=11       q=12       q=13       q=14       q=15       q=16       q=17       q=18       q=19       q=20       q=21       q=22       q=23       q=24\n",
      "Test MSE        65.985091  67.075365  75.850070  68.614055  72.051681  77.651255  80.237003  85.623280  88.091847  90.037087  89.543566  88.571507  84.446137  82.698232  85.086645  89.222751  86.498848  85.654038  84.528418  82.907342  80.484712  79.632375  77.503295  78.043470\n",
      "Test MAE         8.123121   8.189955   8.709195   8.283360   8.488326   8.811995   8.957511   9.253285   9.385726   9.488787   9.462746   9.411244   9.189458   9.093857   9.224242   9.445780   9.300476   9.254947   9.193934   9.105347   8.971327   8.923697   8.803596   8.834222\n",
      "Validation MSE  30.631036  31.375297  37.461806  32.430413  34.806893  38.730776  40.563161  44.418164  46.201061  47.612732  47.254031  46.548610  43.571465  42.318504  44.031888  47.021055  45.049417  44.440319  43.630574  42.468127  40.739341  40.133592  38.626301  39.007920\n",
      "Validation MAE   5.534531   5.601366   6.120605   5.694771   5.899737   6.223405   6.368921   6.664695   6.797136   6.900198   6.874157   6.822654   6.600868   6.505267   6.635653   6.857190   6.711886   6.666357   6.605344   6.516757   6.382738   6.335108   6.215006   6.245632\n"
     ]
    }
   ],
   "source": [
    "# Initialize Results DataFrames\n",
    "results_test = pd.DataFrame(index=[\"Test MSE\", \"Test MAE\"], columns=np.arange(1, 25))\n",
    "results_validate = pd.DataFrame(index=[\"Validation MSE\", \"Validation MAE\"], columns=np.arange(1, 25))\n",
    "\n",
    "# MA Model Fitting and Error Calculation\n",
    "def fit_ma_model(q, train_data, test_data, val_data):\n",
    "    try:\n",
    "        # Fit MA model\n",
    "        model = sm.tsa.ARIMA(train_data[\"PM10_Combined_Trend_Residual\"], order=(0, 0, q))\n",
    "        res = model.fit()\n",
    "\n",
    "        # Forecast for test set\n",
    "        test_forecast = res.forecast(steps=len(test_data))\n",
    "        test_mse = ((test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values) ** 2).mean()\n",
    "        test_mae = np.abs(test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values).mean()\n",
    "\n",
    "        # Forecast for validation set\n",
    "        val_forecast = res.forecast(steps=len(val_data))\n",
    "        val_mse = ((val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values) ** 2).mean()\n",
    "        val_mae = np.abs(val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values).mean()\n",
    "\n",
    "        return test_mse, test_mae, val_mse, val_mae\n",
    "    except Exception as e:\n",
    "        print(f\"Error for q={q}: {e}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "# Run in parallel for MA lags (q) from 1 to 24\n",
    "results = Parallel(n_jobs=-1)(delayed(fit_ma_model)(q, train_data, test_data, val_data) for q in range(1, 25))\n",
    "\n",
    "# Store results in DataFrames\n",
    "for idx, (test_mse, test_mae, val_mse, val_mae) in enumerate(results):\n",
    "    q_value = idx + 1\n",
    "    results_test.loc[\"Test MSE\", q_value] = test_mse\n",
    "    results_test.loc[\"Test MAE\", q_value] = test_mae\n",
    "    results_validate.loc[\"Validation MSE\", q_value] = val_mse\n",
    "    results_validate.loc[\"Validation MAE\", q_value] = val_mae\n",
    "\n",
    "# Combine results into a single DataFrame for display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0)\n",
    "print(final_results.to_string(index=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARMA model für mein laptop aktuell nur mit p und q bis 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 67\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mse_test, mse_validate\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Use joblib's Parallel to run the fit_arma function in parallel for different p, q combinations\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Use joblib's Parallel to run the fit_arma function in parallel for different p, q combinations\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(delayed(fit_arma)(p, q, training, testing, validation) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m25\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m25\u001b[39m))\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Store the results in the DataFrame\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (mse_test, mse_validate) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "File \u001b[1;32mc:\\Users\\nando\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\nando\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nando\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize Results DataFrames\n",
    "results_test = pd.DataFrame(index=[\"Test MSE\", \"Test MAE\"], columns=[(p, q) for p in range(1, 6) for q in range(1, 6)])\n",
    "results_validate = pd.DataFrame(index=[\"Validation MSE\", \"Validation MAE\"], columns=[(p, q) for p in range(1, 6) for q in range(1, 6)])\n",
    "\n",
    "# ARMA Model Fitting and Error Calculation\n",
    "def fit_arma_model(p, q, train_data, test_data, val_data):\n",
    "    try:\n",
    "        # Fit ARMA model\n",
    "        model = sm.tsa.ARIMA(train_data[\"PM10_Combined_Trend_Residual\"], order=(p, 0, q))\n",
    "        res = model.fit()\n",
    "\n",
    "        # Forecast for test set\n",
    "        test_forecast = res.forecast(steps=len(test_data))\n",
    "        test_mse = ((test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values) ** 2).mean()\n",
    "        test_mae = np.abs(test_data[\"PM10_Combined_Trend_Residual\"].values - test_forecast.values).mean()\n",
    "\n",
    "        # Forecast for validation set\n",
    "        val_forecast = res.forecast(steps=len(val_data))\n",
    "        val_mse = ((val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values) ** 2).mean()\n",
    "        val_mae = np.abs(val_data[\"PM10_Combined_Trend_Residual\"].values - val_forecast.values).mean()\n",
    "\n",
    "        return test_mse, test_mae, val_mse, val_mae\n",
    "    except Exception as e:\n",
    "        print(f\"Error for (p, q)=({p}, {q}): {e}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "# Run in parallel for ARMA combinations (p, q) from (1, 1) to (5, 5)\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(fit_arma_model)(p, q, train_data, test_data, val_data) \n",
    "    for p in range(1, 6) for q in range(1, 6)\n",
    ")\n",
    "\n",
    "# Store results in DataFrames\n",
    "for idx, (test_mse, test_mae, val_mse, val_mae) in enumerate(results):\n",
    "    p, q = results_test.columns[idx]\n",
    "    results_test.loc[\"Test MSE\", (p, q)] = test_mse\n",
    "    results_test.loc[\"Test MAE\", (p, q)] = test_mae\n",
    "    results_validate.loc[\"Validation MSE\", (p, q)] = val_mse\n",
    "    results_validate.loc[\"Validation MAE\", (p, q)] = val_mae\n",
    "\n",
    "# Combine results into a single DataFrame for display\n",
    "final_results = pd.concat([results_test, results_validate], axis=0)\n",
    "print(final_results.to_string(index=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
